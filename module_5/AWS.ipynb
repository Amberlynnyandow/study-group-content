{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment - Traditional methods and Cloud Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:01:03.152822Z",
     "start_time": "2021-02-11T17:00:57.818509Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling for Deployment Example\n",
    "\n",
    "This notebook shows the basic outline for training a model, evaluating it, then using it in a \"production\" context to make predictions about new data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load Data\n",
    "\n",
    "This is easy here because I'm using a nice tidy dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:02:30.832097Z",
     "start_time": "2021-02-11T17:02:30.825446Z"
    }
   },
   "outputs": [],
   "source": [
    "# get premade wine dataset from sklearn\n",
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:02:42.514572Z",
     "start_time": "2021-02-11T17:02:42.511009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model to Make Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:03:21.037513Z",
     "start_time": "2021-02-11T17:03:20.970674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's build a model to predict the class of wine\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=100)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model \n",
    "\n",
    "The pickle format is popular for this task in Python. Pickling is a form of serialization or flattening, which basically means converting everything about an object in memory into bits of data that can be stored in a file.\n",
    "\n",
    "**First**, we create a pickle object for our classifier. \n",
    "**Second**, we use the pickle.dump method to convert a Python object hierarchy into a byte stream. This process is also called as serilaization.\n",
    "\n",
    "*pickle.dump(pythonObject, pickleDestination, pickle_protocol=None, *, fix_imports=True)* \n",
    "\n",
    "**Third**, close the file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:05:00.706281Z",
     "start_time": "2021-02-11T17:05:00.700582Z"
    }
   },
   "outputs": [],
   "source": [
    "output_file = open(\"wine_classifier.pickle\", \"wb\") # \"wb\" means \"write as bytes\"\n",
    "pickle.dump(classifier, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model \n",
    "\n",
    "The goal is to take information that was stored in memory at one time, then save it so it can be used later. Here specifically this is useful because training a model is usually a lot slower than using the model to make a prediction, so this saves us from having to re-run that costly operation each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:17:33.751585Z",
     "start_time": "2021-02-11T17:17:33.743508Z"
    }
   },
   "outputs": [],
   "source": [
    "model_file = open(\"wine_classifier.pickle\", \"rb\") # \"rb\" means \"read as bytes\"\n",
    "loaded_model = pickle.load(model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Prediction with the Loaded Model \n",
    "\n",
    "In this section I'm constructing a request JSON that resembles what would come from a user who wants a predicted class of wine based on these feature values. This code would not actually exist in your deployed application, it would be created automatically by whatever protocol generated the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:18:48.559078Z",
     "start_time": "2021-02-11T17:18:48.552204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alcohol': 12.82,\n",
       " 'Malic acid': 3.37,\n",
       " 'Ash': 2.3,\n",
       " 'Alcalinity of ash': 19.5,\n",
       " 'Magnesium': 88.0,\n",
       " 'Total phenols': 1.48,\n",
       " 'Flavanoids': 0.66,\n",
       " 'Nonflavanoid phenols': 0.4,\n",
       " 'Proanthocyanins': 0.97,\n",
       " 'Color intensity': 10.26,\n",
       " 'Hue': 0.72,\n",
       " 'OD280/OD315 of diluted wines': 1.75,\n",
       " 'Proline': 685.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a fake request JSON from the user with all the headings\n",
    "request_json = {}\n",
    "\n",
    "expected_features = (\"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \\\n",
    "        \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \\\n",
    "        \"Proanthocyanins\", \"Color intensity\", \"Hue\", \\\n",
    "        \"OD280/OD315 of diluted wines\", \"Proline\")\n",
    "example_values = [1.282e+01, 3.370e+00, 2.300e+00, 1.950e+01, 8.800e+01, 1.480e+00, \\\n",
    "       6.600e-01, 4.000e-01, 9.700e-01, 1.026e+01, 7.200e-01, 1.750e+00, \\\n",
    "       6.850e+02]\n",
    "\n",
    "for i, feature in enumerate(expected_features):\n",
    "    request_json[feature] = example_values[i]\n",
    "request_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the section that more closely resembles what you might have in your application. I'm checking to make sure that the expected values are in the request_json, transforming them into the right format to make a prediction, then printing out that prediction. In your actual deployed code, you would most likely be returning the response, not printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:19:50.258607Z",
     "start_time": "2021-02-11T17:19:50.248178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 2}\n"
     ]
    }
   ],
   "source": [
    "if request_json and all(feature in request_json for feature in expected_features):\n",
    "    # unpack all of the relevant values from the request into a list\n",
    "    test_value = [request_json[feature] for feature in expected_features]\n",
    "    \n",
    "    # make a prediction from the \"user input\"\n",
    "    predicted_class = int(loaded_model.predict([test_value])[0])\n",
    "    \n",
    "    # construct a response\n",
    "    response_json = {\"prediction\": predicted_class}\n",
    "    print(response_json)\n",
    "else:\n",
    "    print(\"something was missing from the request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productionizing Models as a Career Skill\n",
    "1. Many data scientists don't know how to put machine learning models into production.  \n",
    "2. Putting a model into production is a mandatory skill for data scientists at most small to medium-sized companies.\n",
    "3. Being able to productionize models will make you a much more attractive candidate to employers, and give you a competitive advantage!\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-data-science-and-machine-learning-engineering-online-ds-ft-100719/master/images/new-venn-diagram.png\" width=60%>\n",
    "\n",
    "> -  A decade ago, productionizing a machine learning model would have meant building your own web server with something like [Flask](http://flask.pocoo.org/) or [Django](https://www.djangoproject.com/) and hosting somewhere, just like you would with any web app. \n",
    "> - Now, we don't even need to worry about things like server code -- instead, we can use preexisting services from AWS that were created specifically to simplify the process of productionizing machine learning solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Computing\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Instructor%20Notebooks/sect_43/image/cloud_PNG27.png\" alt=\"image3\" style = \"width:400px\">\n",
    "\n",
    "\"Simply put, cloud computing is the delivery of computing services—including servers, storage, databases, networking, software, analytics, and intelligence—over the Internet (“the cloud”) to offer faster innovation, flexible resources, and economies of scale. You typically pay only for cloud services you use, helping you lower your operating costs, run your infrastructure more efficiently, and scale as your business needs change.\" - Microsoft Azure\n",
    "\n",
    "![microsoft example](https://miro.medium.com/max/624/1*QmV2VDvgIquNx-Daxcdddw.png)\n",
    "\n",
    "Most cloud computing services fall into four broad categories: infrastructure as a service (IaaS), platform as a service (PaaS), serverless, and software as a service (SaaS). These are sometimes called the cloud computing \"stack\" because they build on top of one another. Knowing what they are and how they’re different makes it easier to accomplish your business goals.\n",
    "\n",
    "### Solves many problems:\n",
    "\n",
    "- How can I keep my data secure yet accessible remotely?\n",
    "- How can I pay less for software licenses?\n",
    "- What if I need more server space in the future?\n",
    "- I have more data to analyze than can fit on my computer. What can I do?\n",
    "- My model has taken three days to run. Is there a faster way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS is the Most Popular & It is Intimidating!\n",
    "\n",
    "If you want:\n",
    "- to work from a Jupyter notebook locally\n",
    "- to keep your analysis in a Jupyter notebook\n",
    "- to store your work on git as well\n",
    "- to not concerned about access or keeping data private\n",
    "- the easiest and fastest solution to getting our notebook in the cloud\n",
    "\n",
    "### Focus on the last 2 questions \n",
    "- **I have more data to analyze than can fit on my computer. What can I do?**\n",
    "- **My model has taken three days to run. Is there a faster way?**\n",
    "\n",
    "So you will likely only use **S3**, **Sagemaker**, and **IAM**. \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Instructor%20Notebooks/sect_43//image/aws_focus.png\" alt=\"foci\" style = \"width:90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage \n",
    "\n",
    "<img src=\"https://pngimg.com/uploads/bucket/bucket_PNG7777.png\" alt=\"bucket\" style = \"text-align:left;width:200px;float:none\">\n",
    "\n",
    "#### Buckets defined\n",
    "\n",
    "[by PC Mag](https://www.pcmag.com/encyclopedia/term/bucket)\n",
    "\n",
    "> A customer-defined storage area in a cloud-based storage system such as Amazon's S3 or Google Storage. Each bucket can be divided into folders. Customers are not charged for the buckets themselves, only when data reside within them. See S3 cloud storage and Google Storage.\n",
    "\n",
    "#### S3 stands for _Amazon Simple Storage Service_\n",
    "Amazon uses [S3 buckets](https://aws.amazon.com/s3/) for the most general form of object storage.\n",
    "\n",
    "<!---\n",
    "<img src=\"https://cdn.worldvectorlogo.com/logos/aws-s3.svg\"></br>--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials \n",
    "\n",
    "![credentials](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRvaB5OvGWguYHBlVyagwofOP9kX0h5HqtbcIa02MyAVs_XS90McA&s)\n",
    "\n",
    "#### Credentials Defined:\n",
    "\n",
    "[From AWS](https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html)\n",
    "\n",
    "> When you interact with AWS, you specify your AWS security credentials to verify who you are and whether you have permission to access the resources that you are requesting. AWS uses the security credentials to authenticate and authorize your requests.\n",
    "\n",
    ">For example, if you want to download a specific file from an Amazon Simple Storage Service (Amazon S3) bucket, your credentials must allow that access. If your credentials aren't authorized to download the file, AWS denies your request.\n",
    "\n",
    "#### Our approach to credentials:\n",
    "\n",
    "Make everything public. </br>\n",
    "But we will still have to work with **IAM** a bit to make things talk to each other. \n",
    "\n",
    "<img src=\"https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png\" alt=\"aws\" style =\"text-align:center;width:250px;float:none\" ></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region\n",
    "\n",
    "<img src=\"https://www.concurrencylabs.com/img/posts/9-choose-region-wisely/choose-your-aws-region.png\" wiodth=30%></br>\n",
    "\n",
    "#### Regions Defined:\n",
    "[from AWS documentation](https://aws.amazon.com/about-aws/global-infrastructure/regions_az/):\n",
    ">AWS has the concept of a Region, which is a physical location around the world where we cluster data centers. We call each group of logical data centers an Availability Zone. Each AWS Region consists of multiple, isolated, and physically separate AZ's within a geographic area...\n",
    "\n",
    ">Each AZ has independent power, cooling, and physical security and is connected via redundant, ultra-low-latency networks. AWS customers focused on high availability can design their applications to run in multiple AZ's to achieve even greater fault-tolerance. AWS infrastructure Regions meet the highest levels of security, compliance, and data protection.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Instructor%20Notebooks/sect_43//image/aws_regions_facts.png\" alt=\"aws_regions\" style =\"text-align:center;width:500px;float:none\" >\n",
    "\n",
    "- Each time you create a new \"service\" in AWS, you need to define its region.\n",
    "- Each region is a separate geographic area and is completely independent\n",
    "- Each Amazon region is designed to be completely isolated from the other regions & helps achieve the greatest possible fault tolerance and stability\n",
    "- Communication between regions is across the public Internet and appropriate measures should be taken to protect the data using encryption\n",
    "- Data transfer between regions is charged at the Internet data transfer rate for both the sending and the receiving instance\n",
    "- Resources aren’t replicated across regions unless done explicitly\n",
    "\n",
    "Here are some real factors impacted by your choice of region:\n",
    "\n",
    "    - Latency\n",
    "    - Cost\n",
    "    - Legal Compliance\n",
    "    - Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Sagemaker\n",
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/04/24/SageMaker.jpg\" alt=\"sagemaker\" style =\"text-align:center;width:250px;float:none\" ></br>\n",
    "\n",
    "> ***SageMaker is a platform created by Amazon to centralize all the various services related to Data Science and Machine Learning. If you're a data scientist working on AWS, chances are that you'll be spending most (if not all) of your time in SageMaker getting things done.***\n",
    "\n",
    "\n",
    "> * Amazon has centralized all of the major data science services inside **_Amazon SageMaker_**. SageMaker provides numerous services for things such as:\n",
    "    * Data Labeling\n",
    "    * Cloud-based Notebooks\n",
    "    * Training and Model Tuning\n",
    "    * Inference\n",
    "    \n",
    "#### SageMaker Components\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-introduction-to-aws-sagemaker-online-ds-ft-100719/master/images/use_cases.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Process \n",
    "\n",
    "When productionizing a machine learning model using AWS, you'll typically use the following workflow:\n",
    "\n",
    "1. Explore and preprocess data\n",
    "2. Build SageMaker container (Docker)\n",
    "3. Test training and inference code on your local machine \n",
    "4. Train and deploy model with SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "   - [Canvas Lesson: AWS Ecosystem](https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem) (has account/IAM setup)\n",
    "   - [Canvas Lesson: Intro to Sagemaker](https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker)\n",
    "   - [Canvas Lesson: Productionizing Models with SageMaker](https://learn.co/tracks/module-4-data-science-career-2-1/big-data-deep-learning-and-natural-language-processing/section-43-operationalizing-code-and-aws/productionizing-a-model-with-docker-and-sagemaker)\n",
    "   - **[AWS: Official SageMaker TutorialRepo](https://github.com/aws-samples/amazon-sagemaker-keras-text-classification)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
