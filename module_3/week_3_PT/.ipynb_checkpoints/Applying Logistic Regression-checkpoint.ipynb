{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:19:44.346566Z",
     "start_time": "2020-05-12T16:19:42.700955Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:19:46.896579Z",
     "start_time": "2020-05-12T16:19:46.828539Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/amberyandow/Downloads/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:19:50.202503Z",
     "start_time": "2020-05-12T16:19:50.183702Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:21:11.932872Z",
     "start_time": "2020-05-12T16:21:11.916256Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:21:40.004216Z",
     "start_time": "2020-05-12T16:21:39.959808Z"
    }
   },
   "outputs": [],
   "source": [
    "df['country'] = df['country'].replace(' ?',np.nan)\n",
    "df['workclass'] = df['workclass'].replace(' ?',np.nan)\n",
    "df['occupation'] = df['occupation'].replace(' ?',np.nan)\n",
    "\n",
    "df.dropna(how='any',inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:26:05.838503Z",
     "start_time": "2020-05-12T16:26:05.825338Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert dependent variable to binomial integer \n",
    "salary_map={' <=50K':1,' >50K':0}\n",
    "df['salary']=df['salary'].map(salary_map).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:51:10.143316Z",
     "start_time": "2020-05-12T15:51:10.032995Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='salary', data = df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:51:12.666662Z",
     "start_time": "2020-05-12T15:51:12.546601Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(df['sex'],hue=df['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:51:14.610146Z",
     "start_time": "2020-05-12T15:51:14.493107Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y='age',x='salary',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:27:39.264811Z",
     "start_time": "2020-05-12T16:27:39.224115Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:27:43.860906Z",
     "start_time": "2020-05-12T16:27:43.822256Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:33:22.870200Z",
     "start_time": "2020-05-12T16:33:22.840179Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['salary'], axis=1)\n",
    "y = df['salary']\n",
    "\n",
    "split_size = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=split_size,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:08:44.563270Z",
     "start_time": "2020-05-12T17:08:44.559370Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:33:52.019667Z",
     "start_time": "2020-05-12T16:33:52.017195Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train dataset: {0}{1}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Test dataset: {0}{1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:39:59.964934Z",
     "start_time": "2020-05-12T16:39:59.858952Z"
    }
   },
   "outputs": [],
   "source": [
    "#create an instance and fit the model \n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:49:56.103918Z",
     "start_time": "2020-05-12T16:49:56.085288Z"
    }
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "prediction = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:50:33.318705Z",
     "start_time": "2020-05-12T16:50:33.290648Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('-'*40)\n",
    "print('Accuracy Score:')\n",
    "print(accuracy_score(y_test, prediction))\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "#what's happening here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:08:21.171822Z",
     "start_time": "2020-05-12T17:08:19.029926Z"
    }
   },
   "outputs": [],
   "source": [
    "#smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train) \n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:39:10.602497Z",
     "start_time": "2020-05-12T17:39:10.246391Z"
    }
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(C=100, solver='liblinear')\n",
    "logmodel.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:39:12.444760Z",
     "start_time": "2020-05-12T17:39:12.433621Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:39:13.727719Z",
     "start_time": "2020-05-12T17:39:13.697039Z"
    }
   },
   "outputs": [],
   "source": [
    "print('-'*40)\n",
    "print('Accuracy Score:')\n",
    "print(accuracy_score(y_test, prediction))\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization (Ridge and Lasso)\n",
    "\n",
    "Ridge and Lasso regularizations are also known as ‘shrinkage’ methods, because they reduce or shrink the coefficients in the resulting regression. This reduces the variance in the model: as input variables are changed, the model’s prediction changes less than it would have without the regularization. Why would you want to reduce the variance of a model? To avoid overfit.\n",
    "\n",
    "Regularization is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions.\n",
    "\n",
    "* We must standardize before performing regularization. Why? \n",
    "\n",
    "**Advantages of L1 and L2 regularization:**\n",
    "- L2\n",
    "    - when you have features with high multicollinearity\n",
    "    - reduce model complexity\n",
    "    - features with large coefficients\n",
    "    \n",
    "- L1 \n",
    "    - when you have a lot of small coefficients \n",
    "    - when you have LOTS of features \n",
    "\n",
    "**LogisticRegression has several optional parameters that define the behavior of the model and approach:**\n",
    "\n",
    "**penalty**- is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "**dual**- is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "**tol**- is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "**C**- is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "**fit_intercept**- is a Boolean (True by default) that decides whether to calculate the intercept 𝑏₀ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "**intercept_scaling**- is a floating-point number (1.0 by default) that defines the scaling of the intercept 𝑏₀.\n",
    "\n",
    "**class_weight**- is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "**random_state**- is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "**solver**- is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "**max_iter**- is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "**multi_class**- is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "**verbose**- is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "**warm_start**- is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "**n_jobs**- is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "**l1_ratio**- is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
    "\n",
    "**You should carefully match the solver and regularization method for several reasons:**\n",
    "\n",
    "'liblinear' solver doesn’t work without regularization.\n",
    "'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "'saga' is the only solver that supports elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:37:52.908427Z",
     "start_time": "2020-05-12T17:37:44.390491Z"
    }
   },
   "outputs": [],
   "source": [
    "C = [100, 10, 1, .1, .001]\n",
    "for c in C:\n",
    "    logmodel = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    logmodel.fit(X_train_resampled, y_train_resampled)\n",
    "    print('C:', c)\n",
    "    print('Training accuracy:', logmodel.score(X_train_resampled, y_train_resampled))\n",
    "    print('Test accuracy:', logmodel.score(X_test, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Logistic Regression with Other Models\n",
    "\n",
    "Advantages of logistic regression:\n",
    "\n",
    "- Highly interpretable (if you remember how)\n",
    "- Model training and prediction are fast\n",
    "- Not many parameters to tune\n",
    "- Can perform well with a small number of observations\n",
    "- Outputs well-calibrated predicted probabilities\n",
    "\n",
    "Disadvantages of logistic regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the log-odds of the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods\n",
    "- Can't automatically learn feature interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
