{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is like going to a doctor who asks a series of questions to determine the cause of your symptoms.\n",
    "\n",
    "**Let's Play 20 Questions** \n",
    "\n",
    "**What are some other real life examples(like our doctor) where our society uses a decision tree mentality to come to an answer?** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy and Information Gain \n",
    "The goal is to have our ultimate classes be fully \"ordered\" (for a binary dependent variable, we'd have the 1's in one group and the 0's in the other). So one way to assess the value of a split is to measure how disordered our groups are, and there is a notion of entropy that measures precisely this.\n",
    "\n",
    "The entropy of the whole dataset is given by:\n",
    "\n",
    "$\\large E = -\\Sigma^n_i p_i\\log_2(p_i)$,\n",
    "\n",
    "where $p_i$ is the probability of belonging to the $i$th group, where $n$ is the number of groups (i.e. target values).\n",
    "\n",
    "Entropy will always be between 0 and 1. The closer to 1, the more disordered your group.\n",
    "\n",
    "Let's use the math library's log() function to look at this:\n",
    "[Powerpoint presentation](https://docs.google.com/presentation/d/1kXs3Mi9a3w87J6tzs2sWyxW8kq2eaRQTBgUPKvuf8x8/edit#slide=id.p9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:18:53.900069Z",
     "start_time": "2020-10-21T22:18:53.613113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we start with a 50/50 distribution \n",
    "from math import log\n",
    "import numpy as np \n",
    "entropy = -0.5 * log(0.5, 2) - 0.5 * log(0.5, 2)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:19:45.954828Z",
     "start_time": "2020-10-21T22:19:45.951392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4689955935892812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree will detect a feature that can split into 30/70\n",
    "entropy = -0.1 * log(0.1, 2) - 0.9 * log(0.9, 2)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given split, the information gain is simply the entropy of the parent group less the entropy of the split.\n",
    "\n",
    "For a given parent, then, we maximize our model's performance by minimizing the split's entropy.\n",
    "\n",
    "What we'd like to do then is:\n",
    "\n",
    "to look at the entropies of all possible splits, and\n",
    "to choose the split with the lowest entropy.\n",
    "In practice there are far too many splits for it to be practical for a person to calculate all these different entropies ...\n",
    "\n",
    "... but we can make computers do these calculations for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini Impurity**\n",
    "\n",
    "An alternative metric to entropy comes from the work of Corrado Gini. The Gini Impurity is defined as:\n",
    "\n",
    "$\\large G = 1 - \\Sigma_ip_i^2$, or, equivalently, $\\large G = \\Sigma_ip_i(1-p_i)$.\n",
    "\n",
    "where, again, $p_i$ is the probability of belonging to the $i$th group.\n",
    "\n",
    "Gini Impurity will always be between 0 and 0.5. The closer to 0.5, the more disordered your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:24:56.261764Z",
     "start_time": "2020-10-21T22:24:56.257854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42000000000000004"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gini with 30/70 split \n",
    "1 - (0.7**2 + 0.3**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's practice with some data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:25:43.313721Z",
     "start_time": "2020-10-21T22:25:42.302241Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:25:53.830061Z",
     "start_time": "2020-10-21T22:25:53.817114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:26:46.285649Z",
     "start_time": "2020-10-21T22:26:46.282591Z"
    }
   },
   "outputs": [],
   "source": [
    "#I'm adding a categorical feature \n",
    "df['chest_pain'] = np.random.randint(0,2,size=len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:26:48.407258Z",
     "start_time": "2020-10-21T22:26:48.398933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 10 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "chest_pain                  768 non-null int64\n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 60.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:30:05.962736Z",
     "start_time": "2020-10-21T22:30:05.956287Z"
    }
   },
   "outputs": [],
   "source": [
    "CPandHD = df.loc[(df['chest_pain'] == 1) & (df['Outcome'] == 1)]\n",
    "CPandNHD = df.loc[(df['chest_pain'] == 1) & (df['Outcome'] == 0)]\n",
    "NCPandHD = df.loc[(df['chest_pain'] == 0) & (df['Outcome'] == 1)]\n",
    "NCPandNHD = df.loc[(df['chest_pain'] == 0) & (df['Outcome'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:30:07.331956Z",
     "start_time": "2020-10-21T22:30:07.329112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "260\n",
      "123\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(len(CPandHD))\n",
    "print(len(CPandNHD))\n",
    "print(len(NCPandHD))\n",
    "print(len(NCPandNHD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:43:36.816663Z",
     "start_time": "2020-10-21T22:43:36.811901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4480568267194864 is the gini impurity for the no chest pain leaf\n",
      "0.4596860234720318 is the gini impurity for the chest pain leaf\n"
     ]
    }
   ],
   "source": [
    "#lets calculate gini impurity for each leaf node \n",
    "NCP_leaf = 1 - (123/(123+240))**2 - (240/(123+240))**2\n",
    "CP_leaf = 1 - (145/(145+260))**2 - (260/(145+260))**2\n",
    "print(f\"{NCP_leaf} is the gini impurity for the no chest pain leaf\")\n",
    "print(f\"{CP_leaf} is the gini impurity for the chest pain leaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to calculate the total gini impurity for this root node to determine if it should be used as the root. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:44:08.013279Z",
     "start_time": "2020-10-21T22:44:07.999326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4542171875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating total gini impurity for chest pain \n",
    "total_giniCP = ((len(NCPandHD&NCPandNHD)/768)*.4481) + ((len(CPandHD&CPandNHD)/768)*.4597)\n",
    "total_giniCP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is done for each of our features and the feature with the lowest gini impurity score will become the root node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:53:59.542220Z",
     "start_time": "2020-10-21T22:53:59.536012Z"
    }
   },
   "outputs": [],
   "source": [
    "#create numpy arrays for predictors and target variables \n",
    "X = df.drop('Outcome',axis=1).values\n",
    "y = df['Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:54:04.531073Z",
     "start_time": "2020-10-21T22:54:04.526223Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:54:43.544783Z",
     "start_time": "2020-10-21T22:54:43.535820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:54:46.544320Z",
     "start_time": "2020-10-21T22:54:46.532030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Accuracy Score:\n",
      "0.6926406926406926\n",
      "----------------------------------------\n",
      "Confusion Matrix:\n",
      "[[117  29]\n",
      " [ 42  43]]\n",
      "----------------------------------------\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       146\n",
      "           1       0.60      0.51      0.55        85\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.67      0.65      0.66       231\n",
      "weighted avg       0.68      0.69      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*40)\n",
    "print('Accuracy Score:')\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T22:58:18.215182Z",
     "start_time": "2020-10-21T22:58:18.210470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 29, 42, 43)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T20:17:00.326884Z",
     "start_time": "2020-05-18T20:17:00.323518Z"
    }
   },
   "outputs": [],
   "source": [
    "#brew install graphviz\n",
    "#pip install -U pydotplus\n",
    "\n",
    "#For installing graphviz on windows use the url below \n",
    "#https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/20971549/How+to+install+Graphviz+software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Tree \n",
    "\n",
    "**You will likely need to run the cell above before you can use the following code. Export_graphviz converts our classifier into a dot file and pydotplus converts the dot file in a png which can then be displayed into the notebook.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T23:11:26.642704Z",
     "start_time": "2020-10-21T23:11:26.395515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amberyandow/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 8 does not match number of features, 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3c8bb604479f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m     10\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 special_characters=True,feature_names = col_names,class_names=['0','1'])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             precision=precision)\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    399\u001b[0m                                  \u001b[0;34m\"does not match number of features, %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                  % (len(self.feature_names),\n\u001b[0;32m--> 401\u001b[0;31m                                     decision_tree.n_features_))\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;31m# each part writes to out_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of feature_names, 8 does not match number of features, 9"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "col_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
    "             'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = col_names,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This unpruned tree is not very interpretable. Let's prune these trees and see if we get a better output.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning \n",
    "\n",
    "![](https://miro.medium.com/max/1136/1*3MDxpY_pIMs0yb4dc55KpQ.jpeg)\n",
    "\n",
    "[Great Medium Article that thoroughly goes over each hyperparameter](https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T18:47:48.488573Z",
     "start_time": "2020-05-20T18:47:48.482827Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T18:47:49.455788Z",
     "start_time": "2020-05-20T18:47:49.443446Z"
    }
   },
   "outputs": [],
   "source": [
    "print('-'*40)\n",
    "print('Accuracy Score:')\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('-'*40)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('-'*40)\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T18:48:07.319486Z",
     "start_time": "2020-05-20T18:48:06.206747Z"
    }
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = col_names,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T18:55:37.321618Z",
     "start_time": "2020-05-20T18:55:37.317153Z"
    }
   },
   "outputs": [],
   "source": [
    "top_feats = clf.feature_importances_\n",
    "top_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T18:55:58.090927Z",
     "start_time": "2020-05-20T18:55:57.956297Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# creating list of column names\n",
    "feat_names=list(col_names)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(top_feats)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [feat_names[i] for i in indices]\n",
    "\n",
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), top_feats[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros & Cons \n",
    "[Scikit-Learn](https://scikit-learn.org/stable/modules/tree.html#tree)\n",
    "\n",
    "**Pros**\n",
    "- East to interpret \n",
    "- Easily capture non-linear patterns \n",
    "- No need to normalize columns \n",
    "- feature engineering/importance \n",
    "- Non-parametric/no assumptions \n",
    "\n",
    "**Cons**\n",
    "- Sensitive to noisy data(tends to overfit), can be reduced with tuning \n",
    "- Sensitive to variance, can be reduced by bagging/boosting \n",
    "- Biased when you have imbalanced data(can be fixed with smote) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
