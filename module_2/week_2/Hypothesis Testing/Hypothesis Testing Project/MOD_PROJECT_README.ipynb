{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Module 3 -  Final Project Specifications\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we'll review all the guidelines and specifications for the final project for Module 3.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* Understand all required aspects of the Final Project for Module 3\n",
    "* Understand all required deliverables\n",
    "* Understand what constitutes a successful project\n",
    "\n",
    "### Final Project Summary\n",
    "\n",
    "Another module down--you're half way there!\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-curriculum/dsc-mod-3-project/master/halfway-there.gif'>\n",
    "\n",
    "For the culmination of Module 3, you just need to complete the final project!\n",
    "\n",
    "### The Project\n",
    "\n",
    "For this project, you'll be working with the Northwind database--a free, open-source dataset created by Microsoft containing data from a fictional company. You probably remember the Northwind database from our section on Advanced SQL. Here's the schema for the Northwind database:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-curriculum/dsc-mod-3-project/master/Northwind_ERD_updated.png'>\n",
    "\n",
    "The goal of this project is to test your ability to gather information from a real-world database and use your knowledge of statistical analysis and hypothesis testing to generate analytical insights that can be of value to the company.\n",
    "\n",
    "## The Deliverables\n",
    "\n",
    "The goal of your project is to query the database to get the data needed to perform a statistical analysis.  In this statistical analysis, you'll need to perform a hypothesis test (or perhaps several) to answer the following question:\n",
    "\n",
    "**_Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?_**\n",
    "\n",
    "In addition to answering this question with a hypothesis test, you will also need to come up with **_at least 3 other hypotheses to test on your own_**.  These can by anything that you think could be imporant information for the company.\n",
    "\n",
    "For this hypothesis, be sure to specify both the **_null hypothesis_** and the **_alternative hypothesis_** for your question.  You should also specify if this is one-tail or a two-tail test.\n",
    "\n",
    "For online students, there will be four deliverables for this project:\n",
    "\n",
    "1. A **_Jupyter Notebook_** containing any code you've written for this project. This work will need to be pushed to your GitHub repository in order to submit your project.\n",
    "2. An organized **README.md** file in the GitHub repository that describes the contents of the repository. This file should be the source of information for navigating through the repository.\n",
    "3. A **_[Blog Post](https://github.com/learn-co-curriculum/dsc-welcome-blogging)_**.\n",
    "4. An **_\"Executive Summary\" PowerPoint Presentation_** that explains the hypothesis tests you ran, your findings, and their relevance to company stakeholders.  \n",
    "\n",
    "Note: On-campus students may have different delivarables, please speak with your instructor. \n",
    "\n",
    "### Jupyter Notebook Must-Haves\n",
    "\n",
    "For this project, your Jupyter Notebook should meet the following specifications:\n",
    "\n",
    "**_Organization/Code Cleanliness_**\n",
    "\n",
    "* The notebook should be well organized, easy to follow, and code is commented where appropriate.  \n",
    "<br>  \n",
    "    * Level Up: The notebook contains well-formatted, professional looking markdown cells explaining any substantial code. All functions have docstrings that act as professional-quality documentation.  \n",
    "<br>      \n",
    "* The notebook is written to technical audiences with a way to both understand your approach and reproduce your results. The target audience for this deliverable is other data scientists looking to validate your findings.  \n",
    "<br>    \n",
    "* Any SQL code written to source data should also be included.  \n",
    "\n",
    "**_Findings_**\n",
    "\n",
    "* Your notebook should clearly show how you arrived at your results for each hypothesis test, including how you calculated your p-values.   \n",
    "<br>\n",
    "* You should also include any other statistics that you find relevant to your analysis, such as effect size.\n",
    "\n",
    "### Blog Post Must-Haves\n",
    "\n",
    "Refer back to the [Blogging Guidelines](https://github.com/learn-co-curriculum/dsc-welcome-blogging) for the technical requirements and blog ideas.\n",
    "\n",
    "\n",
    "### Executive Summary Must-Haves\n",
    "\n",
    "Your presentation should:\n",
    "\n",
    "* Contain between 5-10 professional quality slides detailing:\n",
    "<br>  \n",
    "    * A high-level overview of your methodology  \n",
    "    <br>  \n",
    "    * The results of your hypothesis tests  \n",
    "    <br>  \n",
    "    * Any real-world recommendations you would like to make based on your findings (ask yourself--why should the executive team care about what you found? How can your findings help the company?)  \n",
    "    <br>  \n",
    "* Take no more than 5 minutes to present  \n",
    "<br>  \n",
    "* Avoid technical jargon and explain results in a clear, actionable way for non-technical audiences.  \n",
    "\n",
    "## Grading Rubric \n",
    "\n",
    "Online students can find a PDF of the grading rubric for this project [here](https://github.com/learn-co-curriculum/dsc-mod-3-project/blob/master/module3_project_rubric.pdf). _Note: On-campus students may have different requirements, please speak with your instructor._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T23:05:32.547907Z",
     "start_time": "2020-01-30T23:05:32.537079Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hypothesis Testing Guide\n",
       "\n",
       "## Resources\n",
       "\n",
       "### Overivews/Cheatsheets\n",
       "\n",
       "- [CodeAcademy Hypothesis Testing Slideshow](https://drive.google.com/open?id=1p4R2KCErq_iUO-wnfDrGPukTgQDBNoc7)\n",
       "- [Cheatsheet: Hypothesis Testing with Scipy](https://drive.google.com/open?id=1EY4UCg20HawWlWa50M2tFauoKBQcFFAW)\n",
       "\n",
       "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
       "\n",
       "#### Trustable Stat References\n",
       "\n",
       "- [Graphpad Prism's Stat Guide](https://www.graphpad.com/guides/prism/8/statistics/index.htm)\n",
       "- [LAERD Statistics Test Selector](https://statistics.laerd.com/premium/sts/index.php)\n",
       "\n",
       "___\n",
       "\n",
       "# Choosing the Correct Hypothesis Test\n",
       "\n",
       "## STEP 0: Stating our Hypothesis\n",
       "\n",
       "- **Before selecting the correct hypothesis test, you must first officially state your null hypothesis ($H_0$) and alternative hypothesis ($H_A$ or $H_1$)**\n",
       "\n",
       "- **Before stating your hypotheses, ask yourself**\n",
       "    1. What question am I attempting to answer?\n",
       "    2. What metric/value do I want to measure to answer this question?\n",
       "    3. Do I expect the groups to be different in a specific way? (i.e. one group greater than the other).\n",
       "        - Or do I just think they'll be different, but don't know how?\n",
       "\n",
       "- **Now formally declare your hypotheses after asking yourself the questions above:**\n",
       "\n",
       "    - $H_1$ :  \n",
       "\n",
       "    - $H_0$ : \n",
       "\n",
       "\n",
       "\n",
       "## STEP 1: Determine the category/type of test based on your data.\n",
       "\n",
       "### Q1: What type of data do I have (Numeric or categorical?)\n",
       "\n",
       "### Q2: How many samples/groups am I comparing?\n",
       "\n",
       "- Using the answers to the above 2 questions: select the type of test from this table.\n",
       "\n",
       "| What type of comparison? | Numeric Data | Categorical Data|\n",
       "| --- | --- | --- |\n",
       "|Sample vs Known Quantity/Target|1 Sample T-Test| Binomial Test|\n",
       "|2 Samples | 2 Sample T-Test| Chi-Square|\n",
       "|More than 2| ANOVA and/or Tukey | Chi Square|\n",
       "\n",
       "## STEP 2:  Do we meet the assumptions of the chosen test?\n",
       "\n",
       "### ASSUMPTIONS SUMMARY\n",
       "\n",
       "\n",
       "- [One-Sample T-Test](https://statistics.laerd.com/spss-tutorials/one-sample-t-test-using-spss-statistics.php)\n",
       "    - No significant outliers\n",
       "    - Normality\n",
       "\n",
       "- [Independent t-test (2-sample)](https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php)\n",
       "    - No significant outliers\n",
       "    - Normality\n",
       "    - Equal Variance\n",
       "\n",
       "- [One Way ANOVA](https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php)\n",
       "    - No significant outliers\n",
       "    - Equal variance\n",
       "    - Normality\n",
       "\n",
       "- [Chi-Square test](https://statistics.laerd.com/spss-tutorials/chi-square-test-for-association-using-spss-statistics.php)\n",
       "    - Both variables are categorical\n",
       "\n",
       "\n",
       "### HOW TO: TEST ASSUMPTIONS AND SELECT CORRECT TEST\n",
       "\n",
       "#### 0. Check for & Remove Outliers\n",
       "\n",
       "\n",
       "- Required for 1-sample t-test and ANOVA.\n",
       "- Use one of the two methods below to identify outliers:\n",
       "    - Use Tukey's interquartile range rule.\n",
       "    - Use absolutely value of Z-scores >3 as rule.\n",
       "- CAUTION: Tukey's IQR method removes more outliers than z-scores. Take care in choosing the appropriate outlier removal.\n",
       "\n",
       "#### 1. **Test Assumption of  Normality**\n",
       "\n",
       "- Use either of the following tests:\n",
       "    - D'Agostino-Pearson's normality test<br>\n",
       "    ```scipy.stats.normaltest```\n",
       "    - Shapiro-Wilik Test<br>\n",
       "    ```scipy.stats.shapiro```<br>\n",
       "\n",
       "\n",
       "- **1A. If you have normal data:**\n",
       "\n",
       "    - **Move onto assumption \\#2**, testing assumption of equal variance.\n",
       "    \n",
       "    \n",
       "- **1B. If you don't have normal data:** \n",
       "    \n",
       "    > **Check if your group sizes (n) are big enough to safely ignore normality assumption? (see table below)**\n",
       "\n",
       "    - **If your N is big enough:**\n",
       "        - **Move onto assumption \\#2**, testing assumption of equal variance. \n",
       "   - **If you group N's are NOT large enough**:  \n",
       "        - **Move onto step 3.**, selecting the non-parametric version of your t-test\n",
       "\n",
       "| Parametric Test| Sample size guidelines for nonnormal data| \n",
       "| --- | --- |\n",
       "| 1-sample t test| Greater than 20|\n",
       "| 2-sample t test| Each group should be greater than 15| \n",
       "| One-Way ANOVA|If have 2-9 groups, each group n >= 15. <br>If have 10-12 groups, each group n>20.|\n",
       "    \n",
       "\n",
       "#### 2. Test for Equal Variance\n",
       "\n",
       " - Levene's Test<br>\n",
       "```scipy.stats.levene```\n",
       "\n",
       "- **If you fail the assumption of equal variance:**\n",
       "    - Use a Welch's T-Test.\n",
       "        - for scipy, add `equal_var=False` to `ttest_ind`\n",
       "        \n",
       "        \n",
       "- **If you pass the assumption of equal variance:**\n",
       "    - Use a regular 2-sample t-test.\n",
       "    - See Final Summary Table at the bottom.\n",
       "    \n",
       "\n",
       "#### 3. Select a non-parametric equivalent of your t-test.\n",
       " \n",
       "\n",
       "> **Table Source: Parametric  T-Tests vs Non-Parametric Alternatives**\n",
       "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
       "\n",
       "- **Select the test from the right Nonparametric column that matches your Parametric t-test.** \n",
       "\n",
       "\n",
       "- See final summary table at bottom for scipy functions. \n",
       "\n",
       "| Parametric tests (means) | Nonparametric tests (medians) |\n",
       " | --- | --- |\n",
       " | 1-sample t test | 1-sample Wilcoxon |\n",
       " | 2-sample t test | Mann-Whitney U test |\n",
       " | One-Way ANOVA | Kruskal-Wallis |\n",
       "\n",
       "### Summary Table - Hypothesis Testing Functions\n",
       "\n",
       "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
       " | --- | --- | --- | --- |\n",
       " | **1-sample t test** |`scipy.stats.ttest_1samp()`|  **1-sample Wilcoxon** |`scipy.stats.wilcoxon`|\n",
       " | **2-sample t test** |`scipy.stats.ttest_ind()` | **Mann-Whitney U test** |`scipy.stats.mannwhitneyu()` |\n",
       " | **One-Way ANOVA** | `scipy.stats.f_oneway()` | **Kruskal-Wallis** | `scipy.stats.kruskal` | \n",
       " \n",
       "\n",
       "## STEP 3: Interpret Result & Post-Hoc Tests\n",
       "\n",
       "- **Perform hypothesis test from summary table above to get your p-value.**\n",
       "\n",
       "- **If p value is < $\\alpha$:**\n",
       "    - Reject the null hypothesis.\n",
       "    - Calculate effect size (e.g. Cohen's $d$)\n",
       "    \n",
       "- **If p<.05 AND you have multiple groups (i.e. ANOVA)**\n",
       "    - **Must run a pairwise Tukey's test to know which groups were significantly different.**\n",
       "    - [Tukey pairwise comparison test](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n",
       "    - `statsmodels.stats.multicomp.pairwise_tukeyhsd`\n",
       "    \n",
       "    \n",
       "- Report statistical power (optional)\n",
       "\n",
       "#### Post-Hoc Functions:\n",
       "\n",
       "| Post-Hoc Tests/Calculatons|Function|\n",
       "|--- | --- |\n",
       "|**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
       "|**Effect Size**| `Cohens_d`|\n",
       "|**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`\n",
       "\n",
       "# SUMMARY TABLES - COMPLETE\n",
       "\n",
       "### Assumption Tests\n",
       " \n",
       "|Assumption test| Function |\n",
       "| --- | --- |\n",
       "| **Normality**| `scipy.stats.normaltest`|\n",
       "| **Equal Variance** | `scipy.stats.levene`|\n",
       "\n",
       "\n",
       "### Hypothesis Tests\n",
       "\n",
       "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
       "| --- | --- | --- | --- |\n",
       "| **1-sample t test** |`scipy.stats.ttest_1samp()`|  **1-sample Wilcoxon** |`scipy.stats.wilcoxon`|\n",
       "| **2-sample t test** |`scipy.stats.ttest_ind()` | **Mann-Whitney U test** |`scipy.stats.mannwhitneyu()`|\n",
       "| **One-Way ANOVA** | `scipy.stats.f_oneway()` | **Kruskal-Wallis** | `scipy.stats.kruskal` | \n",
       "\n",
       " \n",
       " ### Post-Hoc Tests/Calculations\n",
       " \n",
       " | Post-Hoc Tests/Calculatons|Function|\n",
       " |--- | --- |\n",
       " |**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
       " |**Effect Size**| `Cohens_d`|\n",
       " |**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`\n",
       "\n",
       "\n",
       "# SUMMARY: HYPOTHESIS TESTING STEPS\n",
       "\n",
       "- Separate data in group vars.\n",
       "- Visualize data and calculate group n (size)\n",
       "\n",
       "    \n",
       "* Select the appropriate test based on type of comparison being made, the number of groups, the type of data.\n",
       "\n",
       "\n",
       "- For t-tests: test for the assumptions of normality and homogeneity of variance.\n",
       "\n",
       "    1. Check if sample sizes allow us to ignore assumptions, and if not:\n",
       "    2. **Test Assumption Normality**\n",
       "\n",
       "    3. **Test for Homogeneity of Variance**\n",
       "\n",
       "    4. **Choose appropriate test based upon the above** \n",
       "    \n",
       "* **Perform chosen statistical test, calculate effect size, and any post-hoc tests.**\n",
       "    - To perform post-hoc pairwise comparison testing\n",
       "    - Effect size calculation\n",
       "        - Cohen's d\n",
       "\n",
       "\n",
       "# FUNCTIONS FROM STUDY GROUP\n",
       "\n",
       "```python\n",
       "\n",
       "def Cohen_d(group1, group2, correction = False):\n",
       "    \"\"\"Compute Cohen's d\n",
       "    d = (group1.mean()-group2.mean())/pool_variance.\n",
       "    pooled_variance= (n1 * var1 + n2 * var2) / (n1 + n2)\n",
       "\n",
       "    Args:\n",
       "        group1 (Series or NumPy array): group 1 for calculating d\n",
       "        group2 (Series or NumPy array): group 2 for calculating d\n",
       "        correction (bool): Apply equation correction if N<50. Default is False. \n",
       "            - Url with small ncorrection equation: \n",
       "                - https://www.statisticshowto.datasciencecentral.com/cohens-d/ \n",
       "    Returns:\n",
       "        d (float): calculated d value\n",
       "         \n",
       "    INTERPRETATION OF COHEN's D: \n",
       "    > Small effect = 0.2\n",
       "    > Medium Effect = 0.5\n",
       "    > Large Effect = 0.8\n",
       "    \n",
       "    \"\"\"\n",
       "    import scipy.stats as stats\n",
       "    import scipy   \n",
       "    import numpy as np\n",
       "    N = len(group1)+len(group2)\n",
       "    diff = group1.mean() - group2.mean()\n",
       "\n",
       "    n1, n2 = len(group1), len(group2)\n",
       "    var1 = group1.var()\n",
       "    var2 = group2.var()\n",
       "\n",
       "    # Calculate the pooled threshold as shown earlier\n",
       "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
       "    \n",
       "    # Calculate Cohen's d statistic\n",
       "    d = diff / np.sqrt(pooled_var)\n",
       "    \n",
       "    ## Apply correction if needed\n",
       "    if (N < 50) & (correction==True):\n",
       "        d=d * ((N-3)/(N-2.25))*np.sqrt((N-2)/N)\n",
       "    \n",
       "    return d\n",
       "\n",
       "\n",
       "#Your code here\n",
       "def find_outliers_Z(data):\n",
       "    \"\"\"Use scipy to calculate absolute Z-scores \n",
       "    and return boolean series where True indicates it is an outlier.\n",
       "\n",
       "    Args:\n",
       "        data (Series,or ndarray): data to test for outliers.\n",
       "\n",
       "    Returns:\n",
       "        [boolean Series]: A True/False for each row use to slice outliers.\n",
       "        \n",
       "    EXAMPLE USE: \n",
       "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
       "    >> good_data = df[~idx_outs].copy()\n",
       "    \"\"\"\n",
       "    import scipy.stats as stats\n",
       "    ## Calculate z-scores\n",
       "    zs = stats.zscore(data)\n",
       "    \n",
       "    ## Find z-scores >3 awayfrom mean\n",
       "    idx_outs = np.abs(zs)>3\n",
       "    \n",
       "    ## If input was a series, make idx_outs index match\n",
       "    if isinstance(data,pd.Series):\n",
       "        return pd.Series(idx_outs,index=data.index)\n",
       "    else:\n",
       "        return pd.Series(idx_outs)\n",
       "    \n",
       "    \n",
       "    \n",
       "def find_outliers_IQR(data):\n",
       "    \"\"\"Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
       "    and return boolean series where True indicates it is an outlier.\n",
       "    - Calculates the range between the 75% and 25% quartiles\n",
       "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
       "\n",
       "    IQR Range Calculation:    \n",
       "        res = df.describe()\n",
       "        IQR = res['75%'] -  res['25%']\n",
       "        lower_limit = res['25%'] - 1.5*IQR\n",
       "        upper_limit = res['75%'] + 1.5*IQR\n",
       "\n",
       "    Args:\n",
       "        data (Series,or ndarray): data to test for outliers.\n",
       "\n",
       "    Returns:\n",
       "        [boolean Series]: A True/False for each row use to slice outliers.\n",
       "        \n",
       "    EXAMPLE USE: \n",
       "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
       "    >> good_data = df[~idx_outs].copy()\n",
       "    \n",
       "    \"\"\"\n",
       "    df_b=data\n",
       "    res= df_b.describe()\n",
       "\n",
       "    IQR = res['75%'] -  res['25%']\n",
       "    lower_limit = res['25%'] - 1.5*IQR\n",
       "    upper_limit = res['75%'] + 1.5*IQR\n",
       "\n",
       "    idx_outs = (df_b>upper_limit) | (df_b<lower_limit)\n",
       "\n",
       "    return idx_outs\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display,Markdown\n",
    "with open('README.md','r') as file:\n",
    "    display(Markdown(file.read()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python36964bitlearnenvconda5e778df2e0df4e31951cf19db85f0750"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
