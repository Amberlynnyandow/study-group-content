{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-to-Simple-Linear-Regression\" data-toc-modified-id=\"Introduction-to-Simple-Linear-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction to Simple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Goals\" data-toc-modified-id=\"Goals-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Goals</a></span></li><li><span><a href=\"#Statistical-Learning-Theory\" data-toc-modified-id=\"Statistical-Learning-Theory-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Statistical Learning Theory</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples\" data-toc-modified-id=\"Examples-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Examples</a></span></li></ul></li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Modelling</a></span></li><li><span><a href=\"#Simple-Linear-Regression\" data-toc-modified-id=\"Simple-Linear-Regression-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Simple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimating-(&quot;Learning&quot;)-Model-Coefficients\" data-toc-modified-id=\"Estimating-(&quot;Learning&quot;)-Model-Coefficients-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Estimating (\"Learning\") Model Coefficients</a></span></li><li><span><a href=\"#Questions-About-the-Advertising-Data\" data-toc-modified-id=\"Questions-About-the-Advertising-Data-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Questions About the Advertising Data</a></span></li><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Interpreting-Model-Coefficients\" data-toc-modified-id=\"Interpreting-Model-Coefficients-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Interpreting Model Coefficients</a></span></li></ul></li><li><span><a href=\"#Assumptions\" data-toc-modified-id=\"Assumptions-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Assumptions</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#1.-Linearity\" data-toc-modified-id=\"1.-Linearity-1.5.0.1\"><span class=\"toc-item-num\">1.5.0.1&nbsp;&nbsp;</span>1. Linearity</a></span></li><li><span><a href=\"#2.-Normality\" data-toc-modified-id=\"2.-Normality-1.5.0.2\"><span class=\"toc-item-num\">1.5.0.2&nbsp;&nbsp;</span>2. Normality</a></span></li><li><span><a href=\"#3.-Homoscedasticity\" data-toc-modified-id=\"3.-Homoscedasticity-1.5.0.3\"><span class=\"toc-item-num\">1.5.0.3&nbsp;&nbsp;</span>3. Homoscedasticity</a></span></li></ul></li><li><span><a href=\"#Review\" data-toc-modified-id=\"Review-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Review</a></span></li><li><span><a href=\"#On-Thursday\" data-toc-modified-id=\"On-Thursday-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>On Thursday</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Simple Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Goals \n",
    "* Understand the main ideas behind **statistical learning theory**\n",
    "* What is Linear regression? How is it used and implemented with statsmodels? \n",
    "* What are model assumptions and how to test for them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Statistical Learning Theory\n",
    "![](https://media.giphy.com/media/cnLcLJmRfDwcjUzb2d/giphy.gif)\n",
    "The main goal of statistical learning theory is to provide a framework for studying the problem of inference, that is of gaining knowledge, making predictions,making decisions or constructing models from a set of data.\n",
    "Statistical learning also applies a similar concept. There are input data. Input data is transformed. The output, something that needs to be predicted or estimated, is generated.\n",
    "\n",
    "Statistical learning refers to tools and techniques that enable us to understand data better. So, what do we mean by understanding the data better? \n",
    "\n",
    "First we need clarify what types of data we have if we're going to understand it better. \n",
    "\n",
    "1. Independent variables - Data that can be controlled directly\n",
    "2. Dependent variables - Data that cannot be controlled directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples\n",
    "1. **Age vs. Income** \n",
    "![](http://statisticslectures.com/images/scatter2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2. **Or better yet** \n",
    "![](https://miro.medium.com/max/842/1*uGdpT-vLy3lpx0ktkMP9DQ.png)\n",
    "\n",
    "**QUESTION: What other commonly known linear relationships can you think of?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Modelling \n",
    "![](https://media.giphy.com/media/RLVHPJJv7jY1q/giphy.gif)\n",
    "Now that we understand what our inputs are how do we get to the outputs? \n",
    "There is a middle step between our inputs and outputs, transformation. Models are the engines that transform our inputs. They are functions that estimate the output.\n",
    "\n",
    "**Question: what are the parameters of our function?** Remember, parameters are like numerical characteristics of a model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a quantitative output using a single feature (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$ + _error term_\n",
    "\n",
    "What does each term represent?\n",
    "\n",
    "* $y$ is the output\\\n",
    "* $x$ is the feature or input\\\n",
    "* $\\beta_0$ is the y-intercept\\\n",
    "* $\\beta_1$ is the coefficient for x\\\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the model coefficients. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to make predictions. Now, how about that error term?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "Generally speaking, coefficients are estimated using the ordinary least squares(OLS) criterion, which means we must find the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\"):\n",
    "\n",
    "$$\\hat y =  \\hat \\beta_0+ \\hat \\beta_1 x $$\n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_estimating_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**What elements are present in the diagram?**\n",
    "\n",
    "The black dots are the observed values of x and y.\n",
    "The blue line is our least squares line.\n",
    "The red lines are the residuals, which are the distances between the observed values and the least squares line.\n",
    "How do the model coefficients relate to the least squares line?\n",
    "\n",
    "* $\\beta_0$ is the intercept (the value of $y$ when $x$=0)\n",
    "* $\\beta_1$ is the slope (the change in $y$ divided by change in $x$)\n",
    "\n",
    "Here is a graphical depiction of those calculations:\n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_slope_intercept.png)\n",
    "\n",
    "We want to choose the regression line that fits the data the best. We can accomplish this by finding the 2 parameters, m (slope) and b (intercept), that minimizes the SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:35:49.479622Z",
     "start_time": "2020-04-14T16:35:48.488554Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# read data into a DataFrame\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**What are the features/predictors?**\n",
    "\n",
    "*TV:* advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "\n",
    "*Radio:* advertising dollars spent on Radio\n",
    "\n",
    "*Newspaper:* advertising dollars spent on Newspaper\n",
    "\n",
    "**What is the target?**\n",
    "\n",
    "*Sales:* sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:37:25.537905Z",
     "start_time": "2020-04-14T16:37:25.535130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print the shape of the DataFrame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:38:02.825371Z",
     "start_time": "2020-04-14T16:38:02.360823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#There are 200 observations, and thus 200 markets in the dataset.\n",
    "\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3,)\n",
    "data.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1])\n",
    "data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this widget. The company might ask you the following: On the basis of this data, how should we spend our advertising money in the future?\n",
    "\n",
    "This general question might lead you to more specific questions:\n",
    "\n",
    "* Is there a relationship between ads and sales?\n",
    "* How strong is that relationship?\n",
    "* Which ad types contribute to sales?\n",
    "* What is the effect of each ad type of sales?\n",
    "* Given ad spending in a particular market, can sales be predicted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Libraries\n",
    "We will be using Statsmodels for teaching purposes since it has some nice characteristics for linear modeling. However, we recommend that you spend most of your energy on scikit-learn since it provides significantly more useful functionality for machine learning in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:40:59.301610Z",
     "start_time": "2020-04-14T16:40:58.579706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:43:44.269787Z",
     "start_time": "2020-04-14T16:43:44.207641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = 'Sales~TV'\n",
    "model = ols(formula=f, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:52:16.071374Z",
     "start_time": "2020-04-14T16:52:16.066029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:55:52.473647Z",
     "start_time": "2020-04-14T16:55:52.285689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with the minimum and maximum values of TV\n",
    "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
    "print(X_new.head())\n",
    "\n",
    "# make predictions for those x values and store them\n",
    "preds = model.predict(X_new) #predicts the start/end of line\n",
    "print (preds)\n",
    "\n",
    "# first, plot the observed data and the least squares line\n",
    "data.plot(kind='scatter', x='TV', y='Sales')\n",
    "plt.plot(X_new, preds, c='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T16:55:49.526292Z",
     "start_time": "2020-04-14T16:55:48.892711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"TV\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Whats going on in these visuals?**\n",
    "\n",
    "The Y and Fitted vs. X graph plots the dependent variable against our predicted values with a confidence interval. The positive relationship shows that height and weight are correlated, i.e., when one variable increases the other increases.\n",
    "\n",
    "The Residuals versus height graph shows our model's errors versus the specified predictor variable. Each dot is an observed value; the line represents the mean of those observed values. Since there's no pattern in the distance between the dots and the mean value, the OLS assumption of homoskedasticity holds.\n",
    "\n",
    "The Partial regression plot shows the relationship between height and weight, taking in to account the impact of adding other independent variables on our existing height coefficient. You'll later learn how this same graph changes when you add more variables.\n",
    "\n",
    "The Component and Component Plus Residual (CCPR) plot is an extension of the partial regression plot. It shows where the trend line would lie after adding the impact of adding our other independent variables on the weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Interpreting Model Coefficients\n",
    "[For detailed descriptions of statsmodels outputs](https://learn.co/tracks/module-2-data-science-career-2-1/statistics-ab-testing-and-linear-regression/section-18-introduction-to-linear-regression/ordinary-least-squares-in-statsmodels-ols)\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "\n",
    "A \"unit\" increase in TV ad spending is associated with a 0.047537 \"unit\" increase in Sales.\n",
    "\n",
    "Or more clearly: An additional $1,000 spent on TV ads is associated with an increase in sales of 47.537 widgets.\n",
    "\n",
    "Note that if an increase in TV ad spending was associated with a decrease in sales, $\\beta_1$ would be negative.\n",
    "\n",
    "Using the Model for Prediction\n",
    "Let's say that there was a new market where the TV advertising spend was $50,000. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$$$y = 7.032594 + 0.047537 \\times 50$$\n",
    "\n",
    "**Question: How many widgets would we sell without spending any money on advertising?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions \n",
    "\n",
    "Regression is a parametric technique, which means that it uses parameters learned from the data. Because of that, certain assumptions must be made. These assumptions define the complete scope of regression analysis and it is mandatory that the underlying data fulfills these assumptions. If violated, regression makes biased and unreliable predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1. Linearity \n",
    "The assumption that there is a linear relationship between the target and predictors.\n",
    "\n",
    "**How can I check for this?**\\\n",
    "Build a scatterplot of y vs. various predictors.\n",
    "\n",
    "**What can I do if it looks like I'm violating this assumption?**\\\n",
    "* Consider log-scaling your data.\n",
    "* Consider a different type of model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 2. Normality\n",
    "The normality assumption states that the model _residuals_ should follow a normal distribution.\n",
    "**Note**: the normality assumption talks about the model residuals and not about the distributions of the variables!\n",
    "\n",
    "**How can I check for this?**\n",
    "* Check the Omnibus value (This is a test for error normality. The probability is the chance that the errors are normally distributed.)\n",
    "* Build a QQ-Plot.\n",
    "\n",
    "**What can I do if it looks like I'm violating this assumption?**\n",
    "* Consider log-scaling your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T17:10:26.545063Z",
     "start_time": "2020-04-14T17:10:26.400906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "residuals = model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 3. Homoscedasticity \n",
    "The residual errors have the same variance.\n",
    "\n",
    "**How can I check for this?**\n",
    "\n",
    "* Check the Durbin-Watson score (This is a test for error homoskedasticity. We're looking for values between ~1.5 and ~2.5).\n",
    "* Build an error plot, i.e. a plot of errors for a particular predictor (vs. the values of that predictor).\n",
    "\n",
    "**What can I do if it looks like I'm violating this assumption?**\n",
    "\n",
    "* Consider dropping extreme values.\n",
    "* Consider log-scaling your target.\n",
    "* Consider a different type of model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Review\n",
    "![](https://convertwithcontent.com/wp-content/uploads/2014/04/review-the-results-of-your-a-b-split-test-300x225.jpg)\n",
    "* Statistical learning theory deals with the problem of finding a predictive function based on data\n",
    "* A loss function calculates how well a given model represents the relationship between data values\n",
    "* A linear regression is simply a (straight) line of best fit for predicting a continuous value (y = mx + c)\n",
    "* The Coefficient of Determination (R Squared) can be used to determine how well a given line fits a given data set\n",
    "* Certain assumptions must hold true for a least squares linear regression to be useful - linearity, normality and homoskedasticity\n",
    "* Q-Q plots can check for normality in residual errors\n",
    "* The omnibus-value can be used to test for normality\n",
    "* Durbin-watson score and error plots can check for homoskedasticity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### On Thursday\n",
    "We will take a look at multiple linear regression with statsmoels and skikit learn. With discussions on dealing with multicollinearity, categorical variables, scaling/normalizing, feature creation and model validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
