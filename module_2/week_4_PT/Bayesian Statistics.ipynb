{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "### <h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Bayesian-Reasoning\" data-toc-modified-id=\"Bayesian-Reasoning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Bayesian Reasoning</a></span></li><li><span><a href=\"#A-Famous-Example\" data-toc-modified-id=\"A-Famous-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>A Famous Example</a></span></li><li><span><a href=\"#The-Monty-Hall-Problem\" data-toc-modified-id=\"The-Monty-Hall-Problem-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The Monty Hall Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#Posterior-Probability-that-the-Prize-Is-Behind-Your-Door\" data-toc-modified-id=\"Posterior-Probability-that-the-Prize-Is-Behind-Your-Door-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Posterior Probability that the Prize Is Behind Your Door</a></span></li></ul></li><li><span><a href=\"#Bayes'-Theorem---Example\" data-toc-modified-id=\"Bayes'-Theorem---Example-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Bayes' Theorem - Example</a></span></li><li><span><a href=\"#Review-Normal-Distributions---Example\" data-toc-modified-id=\"Review-Normal-Distributions---Example-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Review Normal Distributions - Example</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:37:26.133928Z",
     "start_time": "2020-04-07T17:37:25.790043Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Reasoning \n",
    "\n",
    "**Historical Relevance**\n",
    "\n",
    "In the early twentieth century, the quantum theory being developed by physicists was saying that the location (etc.) of a particle could be represented by a probabilistic wave function that gave probabilities for the particle to be in one place rather than another. And this question of how to understand these probabilities reared its head. Albert Einstein argued that they could only be interpreted subjectively, but the dominant interpretation today is that there is a kind of indeterminacy in the universe itself.\n",
    "\n",
    "**Objective Probability**\n",
    "\n",
    "The paradigmatic theory of objective probability is frequentism, which says that probabilities are a measure of the long-run behvior of physical systems. To say that a die has a 1/6 chance of coming up \"6\" when tossed, for example, is to say that, in the long run as the number of tosses increases without bound, the number of \"6\"s rolled will constitute one sixth of all tosses.\n",
    "\n",
    "On this point of view, we cannot speak meaningfully of the probability of a single event. Once a die has been rolled, there is no non-trivial probability of its having come up \"6\" or not. Either it did (in which case the probability is 1) or it did not (in which case the probability is 0).\n",
    "\n",
    "Similarly, we cannot speak meaningfully of the probability of a parameter having a certain value, or of a hypothesis being true. The frequentist will reject the idea of a (meaningful) probability of a die being unfairly weighted. Either it is or it is not.\n",
    "\n",
    "**Subjective Probability**\n",
    "\n",
    "The paradigmatic theory of subjective probability is Bayesianism, which says that probabilities are better understood as rational degrees of belief. The standard of rationality is necessary here to assure that these degrees of belief will conform to the probability calculus.\n",
    "\n",
    "If probabilities are degrees of belief, then it does make sense to apply them to parameters or to hypotheses. The probability of a die being unfairly weighted would simply represent what it would be rational to believe about the die with respect to its being weighted or not.\n",
    "\n",
    "Now: Crucially, what it is rational to believe about the die with respect to its being weighted or not is a function of what we know about the die!\n",
    "\n",
    "In particular, if we gain the evidence (or knowledge) that the die has been rolled 100 times and come up \"5\" 90 times, then this would have (or, rather, ought, rationally, to have) a significant impact on our degree of belief with respect to the weightedness of the die. This is the sort of idea that Thomas Bayes had.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Famous Example\n",
    "\n",
    "Suppose some rare disease affects 1 in 100,000 people. There is a test for it, though it is imperfect: 5% of the people who have the disease will test negative and 4% of the people who don't have the disease will test positive for it. You take the test and test positive. Before the test the probability that you had the disease was only 1 in 100,000. But now, with this new information of the positive test, how should you judge the probability that you have the disease?\n",
    "\n",
    "We can use Bayes's Theorem:\n",
    "\n",
    "$\\huge P(h | e) = \\frac{P(e | h)P(h)}{P(e)}$.\n",
    "\n",
    "What are $h$ and $e$ in this case?\n",
    "\n",
    "To calculate the denominator, we'll need to make use of the Rule of Total Evidence:\n",
    "\n",
    "$\\large P(e) = P(e | h_1)P(h_1) + ... + P(e | h_n)P(h_n)$\n",
    "\n",
    "In our case, there are only two possibilities: Either I have the disease or I do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T16:36:53.717932Z",
     "start_time": "2020-04-07T16:36:53.710544Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Monty Hall Problem \n",
    "Bayesian reasoning applies naturally and neatly to the famous Monty Hall Problem. - [video](https://www.khanacademy.org/partner-content/wi-phi/wiphi-metaphysics-epistemology/probability-philosophy/v/the-monty-hall-problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Probability that the Prize Is Behind Your Door\n",
    "Let's calculate the posterior probability that the prize is behind Door #1, given the evidence that Hall shows you that it is not behind Door #2:\n",
    "\n",
    "What is the prior probability that the prize is behind Door #1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T16:51:44.077469Z",
     "start_time": "2020-04-07T16:51:44.073990Z"
    }
   },
   "outputs": [],
   "source": [
    "prior_1 = 1/3\n",
    "prior_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the likelihood of the evidence: What is the probability that Hall would show you that it is not behind Door #2, given the hypothesis that the prize is behind Door #1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T16:52:58.081143Z",
     "start_time": "2020-04-07T16:52:58.078502Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood_1 = 1/2\n",
    "likelihood_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the probability of the evidence itself:\n",
    "\n",
    "There are three salient hypotheses to consider:\n",
    "\n",
    "$h_1$: The prize is behind Door #1.<br/>\n",
    "$h_2$: The prize is behind Door #2.<br/>\n",
    "$h_3$: The prize is behind Door #3.\n",
    "And our evidence is:\n",
    "\n",
    "$e$: Hall shows you that the prize is not behind Door #2.\n",
    "We can calculate the probability as follows:\n",
    "\n",
    "$P(e) = P(e | h_1)\\times P(h_1) + P(e | h_2)\\times P(h_2) + P(e | h_3)\\times P(h_3)$.\n",
    "\n",
    "We've already made the calculation for the first term:\n",
    "\n",
    "$P(e | h_1)\\times P(h_1) = \\frac{1}{2}\\times\\frac{1}{3} = \\frac{1}{6}$.\n",
    "\n",
    "Now:\n",
    "\n",
    "The probability that Hall would show you Door #2, given that the prize is behind Door #2, is zero. (This is by the rules of the game.)\n",
    "\n",
    "The probability that Hall would show you Door #2, given that the prize is behind Door #3, is one. (Here Hall's hand would be forced, since he can, by the rules, show you neither the door that you chose (#1) nor the door with the prize (#3).)\n",
    "\n",
    "So we have:\n",
    "\n",
    "$P(e) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n",
    "\n",
    "We are finally in a position to calculate the posterior! We have:\n",
    "\n",
    "$\\large P(h_1 | e) = \\frac{P(e | h_1)\\times P(h)}{P(e)} = \\frac{1 / 6}{1 / 2} = \\frac{1}{3}$.\n",
    "\n",
    "That is, our updated probability that the prize is behind Door #1 is just the same as the prior. It's still just $\\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior probability that the prize is behind Door #3, given the evidence that Hall has shown you what's behind Door #2, ought to work out to $\\frac{2}{3}$. Let's verify this:\n",
    "\n",
    "What is the prior probability that the prize is behind Door #3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the likelihood: What's the probability that Hall would show you Door #2, given that the prize is behind Door #3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already made our calculation of the evidence. From before we had:\n",
    "\n",
    "$P(e) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n",
    "\n",
    "So now we are in a position to calculate the posterior probability that the prize is behind Door #3. We have:\n",
    "\n",
    "$\\large P(h_3 | e) = \\frac{P(e | h_3)\\times P(h)}{P(e)} = \\frac{1 / 3}{1 / 2} = \\frac{2}{3}$.\n",
    "\n",
    "Given that Hall shows us what's behind Door #2, we should now update our degree of belief that the prize is behind Door #3 to $\\frac{2}{3}$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem - Example \n",
    "\n",
    "Thomas wants to get a new puppy üêï üê∂ üê©. \n",
    "He can choose to get his new puppy either from the pet store or the pound. The probability of him going to the pet store is $0.2$.\n",
    "\n",
    "He can choose to get either a big, medium or small puppy.\n",
    "\n",
    "If he goes to the pet store, the probability of him getting a small puppy is $0.6$. The probability of him getting a medium puppy is $0.3$, and the probability of him getting a large puppy is $0.1$.\n",
    "\n",
    "If he goes to the pound, the probability of him getting a small puppy is $0.1$. The probability of him getting a medium puppy is $0.35$, and the probability of him getting a large puppy is $0.55$.\n",
    "\n",
    "**1)** What is the probability of Thomas getting a small puppy? \n",
    "\n",
    "**2)** Given that he got a large puppy, what is the probability that Thomas went to the pet store? \n",
    "\n",
    "**3)** Given that Thomas got a small puppy, is it more likely that he went to the pet store or to the pound? \n",
    "\n",
    "**4)** What is the prior, posterior and likelihood?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:13:58.386501Z",
     "start_time": "2020-04-07T17:13:58.382847Z"
    }
   },
   "outputs": [],
   "source": [
    "Prior = P(Store)\n",
    "Posterior = P(Store| Large)\n",
    "Likelihood = P(Large| Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Normal Distributions - Example \n",
    "\n",
    "Say we have check totals for all checks ever written at a TexMex restaurant.\n",
    "\n",
    "The distribution for this population of check totals happens to be normally distributed with a population mean of $\\mu = 20$ and population standard deviation of $\\sigma = 2$.\n",
    "\n",
    "**1) Write a function to compute the z-scores for single checks of amount check_amt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:28:11.129079Z",
     "start_time": "2020-04-07T17:28:11.126582Z"
    }
   },
   "outputs": [],
   "source": [
    "def z_score(check_amt):\n",
    "    return(check_amt - 20)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) I go to the TexMex restaurant and get a check for 24 dollars.**\n",
    "\n",
    "Use the function to compute your check's z-score, and interpret the result using the empirical rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:29:43.619157Z",
     "start_time": "2020-04-07T17:29:43.616608Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"My check has a z_score of {}.\".format(z_score(24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Using $\\alpha = 0.05$, is my 25 dollar check significantly greater than the mean? How do you know this?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:37:34.556791Z",
     "start_time": "2020-04-07T17:37:34.551976Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"My check amount has a z_score of {}.\".format(z_score(24)))\n",
    "print(\"The critical threshold z is {}.\".format(round(stats.norm.ppf(.95),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Determine the 95% confidence interval around the mean check total for this population. Interpret your result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T17:42:55.790753Z",
     "start_time": "2020-04-07T17:42:55.787423Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = 20 \n",
    "std = 2\n",
    "conf = (mean - 1.96*std, mean + 1.96*std)\n",
    "print(\"The 95% confidence interval is \", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Imagine that we didn't know how the population of check totals was distributed. How would sampling and the Central Limit Theorem allow us to make inferences on the population mean, i.e. estimate $\\mu, \\sigma$ of the population mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
