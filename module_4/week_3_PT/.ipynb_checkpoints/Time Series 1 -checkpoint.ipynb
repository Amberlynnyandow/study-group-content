{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis \n",
    "\n",
    "In the broadest definition, a time series is any data set where the values are measured at different points in time. Many time series are uniformly spaced at a specific frequency, for example, hourly weather measurements, daily counts of web site visits, or monthly sales totals. Time series can also be irregularly spaced and sporadic, for example, timestamped data in a computer system’s event log or a history of 911 emergency calls. Pandas time series tools apply equally well to either type of time series.\n",
    "\n",
    "The study of time series has arisen because certain sorts of data streams are heavily dependent on the flow of time. Of course, we have not totally ignored time as a feature up to this point. The selling price of a house probably does have some relation to the season or the year as real estate markets grow and decline with certain temporally-indexed economic changes etc. But surely time is not the most important predictor of house price. Square footage would likely be more strongly correlated with price than would date of sale.\n",
    "\n",
    "But there are other sorts of data that more readily lend themselves to a temporal analysis. One canonical example is numbers from a stock exchange: First, data from stock tickers often arrive as numbers anchored to consecutive units of time. I get the selling price for some stock on January 1, say, and the next bit of information I gain will be the selling price for that stock on January 2. (We'll explore this feature of time series below.) Second, and more important, if I'm interested in actually predicting the selling price of a stock for, say, tomorrow, then very likely one piece of very salient (i.e. correlated) information would be the selling price of that stock today.\n",
    "\n",
    "Other examples of this sort of time-dependent data:\n",
    "\n",
    "    * Births/day or year in countries\n",
    "    \n",
    "    * Current trends: Census data/Covid-19/Airline/Zoom stocks/Bitcoin \n",
    "    \n",
    "    * Sales of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.390432Z",
     "start_time": "2020-12-01T22:48:14.175471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load some packages.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.394782Z",
     "start_time": "2020-12-01T22:48:15.392003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that will help us load and\n",
    "# clean up a dataset.\n",
    "\n",
    "def load_trend(trend_name='football', country_code='us'):\n",
    "    df = pd.read_csv('data/google-trends_'\n",
    "                     + trend_name + '_'\n",
    "                     + country_code\n",
    "                     + '.csv').iloc[1:, :]\n",
    "    df.columns = ['counts']\n",
    "    df['counts'] = df['counts'].str.replace('<1', '0').astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.427615Z",
     "start_time": "2020-12-01T22:48:15.396708Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_trend(**{'trend_name': 'data-science', 'country_code': 'us'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `**` syntax is used to pass keywords and values in dictionary form to a function. For more on `*` and `**` (`*args` and `**kwargs`), see [this page](https://www.geeksforgeeks.org/args-kwargs-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.432454Z",
     "start_time": "2020-12-01T22:48:15.429583Z"
    }
   },
   "outputs": [],
   "source": [
    "trends = [\n",
    "    {'trend_name': 'data-science', 'country_code': 'us'},\n",
    "    {'trend_name': 'football', 'country_code': 'us'},\n",
    "    {'trend_name': 'football', 'country_code': 'uk'},\n",
    "    {'trend_name': 'game-of-thrones', 'country_code': 'us'},\n",
    "    {'trend_name': 'pokemon', 'country_code': 'us'},\n",
    "    {'trend_name': 'taxes', 'country_code': 'us'},   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.435632Z",
     "start_time": "2020-12-01T22:48:15.433831Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:15.614446Z",
     "start_time": "2020-12-01T22:48:15.437172Z"
    }
   },
   "outputs": [],
   "source": [
    "trend_dfs = [load_trend(**trend) for trend in trends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.258312Z",
     "start_time": "2020-12-01T22:48:15.616586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see if we can guess which is which just by looking\n",
    "# at their graphs.\n",
    "\n",
    "import matplotlib; matplotlib.style.use('ggplot')\n",
    "\n",
    "fig, axs = plt.subplots(len(trend_dfs), 1, figsize=(8, 10))\n",
    "plt.tight_layout()\n",
    "for i, trend_df in enumerate(trend_dfs):\n",
    "    ax = axs[i]\n",
    "    #ax.set_title(str(trends[i]))\n",
    "    ax.plot(np.array(trend_df.index), trend_df['counts'])\n",
    "    ticks = ax.get_xticks()\n",
    "    ax.set_ylim((0, 100))\n",
    "    ax.set_xticks([tick for tick in ticks if tick%24 == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Time Series Data \n",
    "    - Datetime Objects \n",
    "    - Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.276558Z",
     "start_time": "2020-12-01T22:48:16.261294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and display\n",
    "df_temp = pd.read_csv(\"min_temp.csv\")\n",
    "display(df_temp.head(20))\n",
    "display(df_temp.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data readable as a datetime\n",
    "\n",
    "First, you want to make sure:\n",
    "- Dates are in the index of the DataFrame (helps you with plotting)\n",
    "- That we change the dates in our dataset from \"non-null object\" to \"non-null datetime\" (i.e., change the data type of dates). This can be done using the `to_datetime()` function from Pandas. To make sure Python understands the date correctly, a `format` argument can be passed [as specified in the documentation](https://pandas.pydata.org/pandas-docs/stable/timeseries.html#providing-a-format-argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime Objects\n",
    "\n",
    "These comprise a nice standard way of dealing with times and dates in Python. There is a `datetime` [library](https://docs.python.org/2/library/datetime.html), and inside `pandas` there is a `datetime` module as well as a `to_datetime()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.281741Z",
     "start_time": "2020-12-01T22:48:16.278968Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime(2020, 12, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datetime objects have the parts of a date as attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.285292Z",
     "start_time": "2020-12-01T22:48:16.282993Z"
    }
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime(2020, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.288970Z",
     "start_time": "2020-12-01T22:48:16.286776Z"
    }
   },
   "outputs": [],
   "source": [
    "print(now.year)\n",
    "print(now.month)\n",
    "print(now.day)\n",
    "print(now.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.timedelta()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.293504Z",
     "start_time": "2020-12-01T22:48:16.290739Z"
    }
   },
   "outputs": [],
   "source": [
    "moment = datetime.timedelta(minutes=100)\n",
    "moment.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.297947Z",
     "start_time": "2020-12-01T22:48:16.294959Z"
    }
   },
   "outputs": [],
   "source": [
    "moment.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.303846Z",
     "start_time": "2020-12-01T22:48:16.299550Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.309962Z",
     "start_time": "2020-12-01T22:48:16.305299Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(['2020-12-30', '2020-12-31'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's convert our weather data now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.322265Z",
     "start_time": "2020-12-01T22:48:16.311140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a proper datetime using the string formatting\n",
    "df_temp['Date'] = pd.to_datetime(df_temp['Date'], format='%d/%m/%y')\n",
    "\n",
    "# Make the temporal data as the focus\n",
    "df_temp = df_temp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.333181Z",
     "start_time": "2020-12-01T22:48:16.323748Z"
    }
   },
   "outputs": [],
   "source": [
    "display(df_temp.head(10))\n",
    "display(df_temp.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.341332Z",
     "start_time": "2020-12-01T22:48:16.334399Z"
    }
   },
   "outputs": [],
   "source": [
    "#a simple slice helps to define the range of interest \n",
    "after_1990 = df_temp['1990':]\n",
    "display(after_1990.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T18:10:40.023939Z",
     "start_time": "2020-12-01T18:10:40.012891Z"
    }
   },
   "source": [
    "### Resampling Methods \n",
    "\n",
    "Resampling involves changing the frequency of your time series observations. \n",
    "Two types of resampling are: \n",
    "\n",
    "**Upsampling:** Where you increase the frequency of the samples, such as from minutes to seconds.<br/> \n",
    "**Downsampling:** Where you decrease the frequency of the samples, such as from days to months\n",
    "\n",
    "In both cases, data must be invented. Assume we have a temperature sensor which takes measurements every minute. If we do not need to have a minute-level precision, we can take the average of 60 minute measurements in an hour and show the changes in the temperature hourly. This is down-sampling which means converting to a lower frequency.\n",
    "\n",
    "Resampling can be done using **resample()** or **asfreq()** functions.\n",
    "- **Resample(Downsampling):** Aggregates data based on specified frequency and aggregation function. Downsampling resamples at a lower rate, you may loose information but its more computationally efficient\n",
    "![](https://miro.medium.com/max/453/1*60Xzg45SRqJhFueqtOlQ8Q.png)\n",
    "- **Asfreq(Upsampling):** Selects data based on the specified frequency and returns the value at the end of the specified interval.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.350500Z",
     "start_time": "2020-12-01T22:48:16.342597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average out so we have monthly means (compared to using days)\n",
    "monthly = df_temp.resample('MS')\n",
    "month_mean = monthly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.357197Z",
     "start_time": "2020-12-01T22:48:16.351807Z"
    }
   },
   "outputs": [],
   "source": [
    "print(month_mean.head(10))\n",
    "print(df_temp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.527181Z",
     "start_time": "2020-12-01T22:48:16.358998Z"
    }
   },
   "outputs": [],
   "source": [
    "df_temp['Daily_min'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.765900Z",
     "start_time": "2020-12-01T22:48:16.528508Z"
    }
   },
   "outputs": [],
   "source": [
    "df_temp.resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling\n",
    "\n",
    "Up-sampling is the opposite of down-sampling. The frequency is increased. When we increase the frequency, there will be some missing data.We can leave these missing values blank (missing) or select a method to fill these missing values such as forward fill or backward fill.\n",
    "\n",
    "    - ffill() function is used to fill the missing value in the dataframe. 'ffill' stands for 'forward fill' and will propagate last valid observation forward\n",
    "    - bfill() is used to backward fill the missing values in the dataset. It will backward fill the NaN values that are present in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.777602Z",
     "start_time": "2020-12-01T22:48:16.770628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data to every 12hours but only fill the parts known (blank otherwise)\n",
    "bidaily = df_temp.resample('12H').asfreq()\n",
    "bidaily.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.786144Z",
     "start_time": "2020-12-01T22:48:16.779906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate to every 12hours but fill the parts unknown (no blanks)\n",
    "bidaily = df_temp.resample('12H').ffill()\n",
    "bidaily.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.797094Z",
     "start_time": "2020-12-01T22:48:16.787742Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly = df_temp.resample('1H').ffill()\n",
    "hourly.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends \n",
    "\n",
    "The trends represent an increase or decrease in time-series value over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upward\n",
    "![](https://github.com/learn-co-students/dsc-3-25-05-types-of-trends-online-ds-sp-000/raw/master/index_files/index_15_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downward\n",
    "![](https://github.com/learn-co-students/dsc-3-25-05-types-of-trends-online-ds-sp-000/raw/master/index_files/index_19_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential\n",
    "![](https://github.com/learn-co-students/dsc-3-25-05-types-of-trends-online-ds-sp-000/raw/master/index_files/index_22_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodic \n",
    "![](https://github.com/learn-co-students/dsc-3-25-05-types-of-trends-online-ds-sp-000/raw/master/index_files/index_25_0.png)\n",
    "![](https://github.com/learn-co-students/dsc-3-25-05-types-of-trends-online-ds-sp-000/raw/master/index_files/index_30_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity \n",
    "\n",
    "A time series is said to be stationary if its statistical properties such as mean, variance, etc. remain constant over time. Stationarity is important because most time series models work on the assumption that the time series are stationary. [Learn.co](https://learn.co/tracks/module-4-data-science-career-2-1/big-data-deep-learning-and-natural-language-processing/section-37-working-with-time-series-data/types-of-trends)\n",
    "\n",
    "Which of these series are stationary? \n",
    "![](https://otexts.com/fpp2/fpp_files/figure-html/stationary-1.png)\n",
    "\n",
    "Figure above:\n",
    "(a) Google stock price for 200 consecutive days; \n",
    "(b) Daily change in the Google stock price for 200 consecutive days; \n",
    "(c) Annual number of strikes in the US; \n",
    "(d) Monthly sales of new one-family houses sold in the US; \n",
    "(e) Annual price of a dozen eggs in the US (constant dollars); \n",
    "(f) Monthly total of pigs slaughtered in Victoria, Australia; \n",
    "(g) Annual total of lynx trapped in the McKenzie River district of north-west Canada; \n",
    "(h) Monthly Australian beer production; \n",
    "(i) Monthly Australian electricity production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.804575Z",
     "start_time": "2020-12-01T22:48:16.798492Z"
    }
   },
   "outputs": [],
   "source": [
    "# New York Stock Exchange average monthly returns [1961-1966] from curriculum\n",
    "nyse = pd.read_csv(\"NYSE_monthly.csv\")\n",
    "col_name= 'Month'\n",
    "nyse[col_name] = pd.to_datetime(nyse[col_name])\n",
    "nyse.set_index(col_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.812337Z",
     "start_time": "2020-12-01T22:48:16.806512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generated data \n",
    "years = pd.date_range('2012-01', periods=72, freq=\"M\")\n",
    "index = pd.DatetimeIndex(years)\n",
    "\n",
    "np.random.seed(3456)\n",
    "sales= np.random.randint(-4, high=4, size=72)\n",
    "bigger = np.array([0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,3,3,3,3,\n",
    "                   3,3,3,3,3,3,3,3,7,7,7,7,7,7,7,7,7,7,7,\n",
    "                   11,11,11,11,11,11,11,11,11,11,18,18,18,\n",
    "                   18,18,18,18,18,18,26,26,26,26,26,36,36,36,36,36])\n",
    "\n",
    "data = pd.Series(sales+bigger+6, index=index)\n",
    "ts = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Statistics \n",
    "\n",
    "Take the average of a number of past data points (over a time period). A rolling analysis of a time series model is often used to assess the model's stability over time. When analyzing financial time series data using a statistical model, a key assumption is that the parameters of the model are constant over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:16.947765Z",
     "start_time": "2020-12-01T22:48:16.813783Z"
    }
   },
   "outputs": [],
   "source": [
    "rolmean = ts.rolling(window = 6, center = False).mean()\n",
    "\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "orig = plt.plot(ts, color='blue',label='Original')\n",
    "mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dickey-Fuller Test\n",
    "Statistical test for testing stationarity; $H_0$ is that time series is **not** stationary\n",
    "\n",
    "Doc Resource: http://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.090128Z",
     "start_time": "2020-12-01T22:48:16.949159Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "dftest = adfuller(ts)\n",
    "\n",
    "# Extract and display test results in a user friendly manner\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.094913Z",
     "start_time": "2020-12-01T22:48:17.092023Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can interpret above results based on p-values of result.**\n",
    "\n",
    "- p-value > 0.05 - This implies that time-series is non-stationary.<br/>\n",
    "- p-value <=0.05 - This implies that time-series is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends \n",
    "\n",
    "Goal is to make the time series stationary to use most modeling techniques. When forecasting or predicting the future, most time series models assume that each point is independent of one another. The best indication of this is when the dataset of past instances is stationary. For data to be stationary, the statistical properties of a system do not change over time. This does not mean that the values for each data point have to be the same, but the overall behavior of the data should remain constant. The most common reasons for non-stationary series are seasonality and trends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation \n",
    "\n",
    "Transformations such as logarithms can help to stabilise the variance of a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.372724Z",
     "start_time": "2020-12-01T22:48:17.096423Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "\n",
    "# No transformation\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(ts)\n",
    "plt.xlabel(\"month\", fontsize=16)\n",
    "plt.ylabel(\"monthly sales\", fontsize=16)\n",
    "\n",
    "# Log transformation (linear and heteroscedastic)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(pd.Series(np.log(ts), index=index), color=\"blue\")\n",
    "plt.xlabel(\"month\", fontsize=14)\n",
    "plt.ylabel(\"log(monthly sales)\", fontsize=14)\n",
    "\n",
    "# Square root transformation \n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(pd.Series(np.sqrt(ts), index=index), color=\"green\")\n",
    "plt.xlabel(\"month\", fontsize=14)\n",
    "plt.ylabel(\"sqrt(monthly sales)\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal is to make this more linear; you can tell it's still not stationary. So what can we do?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract the Rolling Mean\n",
    "\n",
    "Generally used to smooth out short-term fluctuations in time series data and highlight long-term trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.498653Z",
     "start_time": "2020-12-01T22:48:17.374582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start with the square root transform\n",
    "data_transform = pd.Series(np.sqrt(ts))\n",
    "\n",
    "rolmean = data_transform.rolling(window = 4).mean()\n",
    "fig = plt.figure(figsize=(11,7))\n",
    "orig = plt.plot(data_transform, color='blue',label='Original')\n",
    "mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean & Standard Deviation')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.503741Z",
     "start_time": "2020-12-01T22:48:17.500600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subtract the moving average from the original data and check head for Nans\n",
    "data_minus_rolmean = data_transform - rolmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.507639Z",
     "start_time": "2020-12-01T22:48:17.505190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the NaN values from timeseries calculated above \n",
    "# (the first few values didn't have a rolling mean)\n",
    "data_minus_rolmean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.672337Z",
     "start_time": "2020-12-01T22:48:17.508881Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(data_minus_rolmean, label='Sales - rolling mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Sales while the rolling mean is subtracted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing\n",
    "\n",
    "Note that the Google stock price was non-stationary in panel (a), but the daily changes were stationary in panel (b). This shows one way to make a non-stationary time series stationary — compute the differences between consecutive observations. This is known as differencing. Differencing can help stabilise the mean of a time series by removing changes in the level of a time series, and therefore eliminating (or reducing) trend and seasonality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:17.808520Z",
     "start_time": "2020-12-01T22:48:17.674224Z"
    }
   },
   "outputs": [],
   "source": [
    "#Example with NYSE\n",
    "data_diff = ts.diff(periods=1)\n",
    "\n",
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(data_diff,label='Sales - differenced')\n",
    "plt.legend()\n",
    "plt.title('Differenced sales series')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:18.463570Z",
     "start_time": "2020-12-01T22:48:17.810325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example - Temperature over a decade\n",
    "data = pd.read_csv(\"min_temp.csv\")\n",
    "data.Date = pd.to_datetime(data.Date)\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "data.plot(figsize=(18,6), linewidth=1, fontsize=14)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Temperature (Degrees Celsius)', fontsize=14);\n",
    "\n",
    "# Period is 365 days (each point)\n",
    "data_diff = data.diff(periods=365)\n",
    "data_diff.plot(figsize=(18,6), linewidth=1, fontsize=14)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Differenced Temperature (Degrees Celsius)', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposing a Time Series with StatsModels \n",
    "Another method where we transform a series into multiple series\n",
    "\n",
    "Commonly:\n",
    "\n",
    "- Seasonal\n",
    "- Trend\n",
    "- Noise/Random/Irregular/Remainder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:18.517855Z",
     "start_time": "2020-12-01T22:48:18.465286Z"
    }
   },
   "outputs": [],
   "source": [
    "taxes_df = load_trend('taxes')\n",
    "taxes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:18.523700Z",
     "start_time": "2020-12-01T22:48:18.520246Z"
    }
   },
   "outputs": [],
   "source": [
    "taxes_df.index = pd.to_datetime(taxes_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:18.535553Z",
     "start_time": "2020-12-01T22:48:18.525960Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(taxes_df['counts'])\n",
    "\n",
    "observed = decomposition.observed\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:18.540024Z",
     "start_time": "2020-12-01T22:48:18.537577Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:19.002915Z",
     "start_time": "2020-12-01T22:48:18.542082Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(411)\n",
    "plt.plot(observed, label='Original', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals are useful in checking whether a model has adequately captured the information in the data. A good forecasting method will yield residuals with the following properties:\n",
    "\n",
    "1. The residuals are uncorrelated. If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts. (we will explore this more in our next SG with an ARIMA model)\n",
    "2. The residuals have zero mean. If the residuals have a mean other than zero, then the forecasts are biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:19.007933Z",
     "start_time": "2020-12-01T22:48:19.004723Z"
    }
   },
   "outputs": [],
   "source": [
    "residual.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For various techincal reasons that won't concern us here, some of the components of the decomposition have NANs at their heads and tails. But we can just use np.nansum() - a function that is used when we want to compute the sum of array elements over a given axis treating (NaNs) as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T22:48:19.024295Z",
     "start_time": "2020-12-01T22:48:19.009505Z"
    }
   },
   "outputs": [],
   "source": [
    "myst = 0\n",
    "for i in range(len(taxes_df['counts'])):\n",
    "    myst += np.nansum(taxes_df['counts'][i] - trend[i] - seasonal[i] - residual[i])\n",
    "myst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "1. Make sure your dates/times are 'non-null datetime' objects not 'non-null objects'.\n",
    "2. Set the datetime object as the index. Why? \n",
    "    - most important aspect of the data\n",
    "    - many of the methods we use for analysis require this\n",
    "3. Deal with missing data. What new options do we have available? \n",
    "    - ffill() - fills missing values with previous value \n",
    "    - bfill() - fills the missing values with the next valid entry\n",
    "    CONS: Trend/seasonal components be influential with these methods\n",
    "4. Use down/up sampling or slicing to manage the data that you want. What are the drawbacks to using down sampling or up sampling? \n",
    "* Downsampling drawback - Introduce missing data. You lose data.\n",
    "* Upsampling drawback - Missing data. Increasing the size of the dataset\n",
    "\n",
    "### Visualizations \n",
    "I strongly recommend completely the [learn.co lab on time series visuals](https://learn.co/tracks/module-4-data-science-career-2-1/big-data-deep-learning-and-natural-language-processing/section-37-working-with-time-series-data/visualizing-time-series-data-lab) \n",
    "\n",
    "### Trends \n",
    "- Upward\n",
    "- Downward\n",
    "- Exponential \n",
    "- Periodic \n",
    "\n",
    "### Stationarity\n",
    "    - Rolling stats - checking to make sure parameters are constant over time(modeling assumption)\n",
    "    - Dickey-Fuller Test \n",
    "    \n",
    "### Removing Trends to satisfy assumptions \n",
    "1. Lof Trasnformations \n",
    "2. Subtract rolling average \n",
    "3. Differencing - Subtract off previous point values (lagging); essentially plots the difference from last point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
