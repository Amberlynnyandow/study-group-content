{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time series may be split into the following components: Base Level + Trend + Seasonality + Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:31:44.411966Z",
     "start_time": "2020-06-12T15:31:43.581836Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from random import gauss as gs\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:32:05.570390Z",
     "start_time": "2020-06-12T15:32:05.561648Z"
    }
   },
   "outputs": [],
   "source": [
    "fb = pd.read_csv('data/google-trends_football_us.csv').iloc[1:, :]\n",
    "fb.columns = ['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:32:18.215219Z",
     "start_time": "2020-06-12T15:32:18.179778Z"
    }
   },
   "outputs": [],
   "source": [
    "fb['counts'] = fb['counts'].replace('<1', '0')\n",
    "fb['counts'] = fb['counts'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:50:02.378464Z",
     "start_time": "2020-06-12T15:50:02.370446Z"
    }
   },
   "outputs": [],
   "source": [
    "fb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series as Both Predictor and Target?\n",
    "\n",
    "Often, the phenomenon we want to capture with a time series is a dataset being correlated with *itself*.\n",
    "\n",
    "Well, of course every dataset is perfectly correlated with itself. But what we're after now is the idea that a series is correlated with *earlier versions* of itself.\n",
    "\n",
    "Consider the problem of trying to predict tomorrow's closing price for some stock on the market. One may consider lots of features, like what sort of company it is to which the stock belongs or whether that company has been in the news recently.\n",
    "\n",
    "But it is very often the case that one of the most helpful predictors of tomorrow's price is *today's* price. And so we want to build a model where one of our predictors is an earlier version of our target.\n",
    "\n",
    "One tool we can use is **`df.rolling()`**, which creates a Rolling object that we can use to calculate statistics dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:43:31.456812Z",
     "start_time": "2020-06-12T15:43:31.448784Z"
    }
   },
   "outputs": [],
   "source": [
    "fb.rolling(window=3).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:46:57.043518Z",
     "start_time": "2020-06-12T15:46:57.034389Z"
    }
   },
   "outputs": [],
   "source": [
    "fb['roll_avg'] = fb.rolling(window=2).mean()\n",
    "\n",
    "fb.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:47:52.991344Z",
     "start_time": "2020-06-12T15:47:52.815973Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(fb.index[:30], fb['counts'][:30])\n",
    "plt.scatter(fb.index[1:31], fb['roll_avg'][1:31]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:49:20.421802Z",
     "start_time": "2020-06-12T15:49:20.410056Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(fb[['roll_avg']][1:], fb['counts'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T15:49:34.523280Z",
     "start_time": "2020-06-12T15:49:34.344914Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(fb.index[1:25], fb['counts'][1:25], label='Data')\n",
    "plt.plot(fb.index[1:25], lr.predict(fb[['roll_avg']][1:25]),\n",
    "         label='Predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation and Partial Autocorrelation\n",
    ">We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.\n",
    "\n",
    ">The basic idea of autocorrelation is simple: See how a series correlates with a \"lagged\" version of itself. If my sequence is $S_0 = (x_0, x_1, x_2, ... , x_n)$, then I can measure the Pearson correlation between the first $n-k + 1$ terms of $S_0$ and $S_{lag} = (x_k, x_{k+1}, x_{k+2}, ... , x_n)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:06:33.570213Z",
     "start_time": "2020-06-12T16:06:33.565402Z"
    }
   },
   "outputs": [],
   "source": [
    "acf(fb['counts'], nlags=20, fft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:06:56.286913Z",
     "start_time": "2020-06-12T16:06:56.128078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot using `.autocorr()`\n",
    "\n",
    "X = np.arange(0, 100, 1)\n",
    "Y = np.zeros(100)\n",
    "for j in X[1:]:\n",
    "    Y[j] = fb['counts'].autocorr(lag=j)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(X, Y)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:07:34.914602Z",
     "start_time": "2020-06-12T16:07:34.749070Z"
    }
   },
   "outputs": [],
   "source": [
    "# To construct the autocorrelation function, we take the covariance of our time series with a lagged version\n",
    "# and then divide by the variance of the series.\n",
    "\n",
    "X = np.arange(0, 100, 1)\n",
    "Y = np.zeros(100)\n",
    "for j in X[1:]:\n",
    "    Y[j] += np.cov(fb['counts'][:-j], fb['counts'][j:])[0, 1] / np.var(fb['counts']) * ((180-j) / 180)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(X, Y)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:08:05.908893Z",
     "start_time": "2020-06-12T16:08:05.764973Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "pd.plotting.autocorrelation_plot(fb['counts']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal bands represent condfidence intervals, which are calculated by taking relevant z-scores of the standard normal distribution and dividing by the square root of the number of observations. What do these intervals mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:10:20.627930Z",
     "start_time": "2020-06-12T16:10:20.487622Z"
    }
   },
   "outputs": [],
   "source": [
    "#We can also use the plot_acf() function from statsmodels:\n",
    "rcParams['figure.figsize'] = 20, 4\n",
    "\n",
    "plot_acf(fb['counts'], lags=125, alpha=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Autocorrelation\n",
    "The idea behind partial Autocorrelation is to compare a series to a lagged version of itself while abstracting away from intermediate values. In effect, this amounts to exploring the correlations among residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:21:47.452954Z",
     "start_time": "2020-06-12T16:21:47.439785Z"
    }
   },
   "outputs": [],
   "source": [
    "pacf(fb['counts'], nlags=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way of computing the partial autocorrelation is by fitting regressions to residuals from a simple dummy model that always predicts the mean. The coefficient of the final term will be the partial autocorrelation for the corresponding number of lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:22:33.792384Z",
     "start_time": "2020-06-12T16:22:33.785136Z"
    }
   },
   "outputs": [],
   "source": [
    "y_tilde = fb['counts'] - fb['counts'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:22:41.522272Z",
     "start_time": "2020-06-12T16:22:41.518382Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = (fb['counts'][:-1] - fb['counts'].mean()).values.reshape(-1, 1)\n",
    "x_2 = (fb['counts'][:-2] - fb['counts'].mean()).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:22:51.572555Z",
     "start_time": "2020-06-12T16:22:51.565684Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(np.concatenate([x_1[1:], x_2], axis=1), y_tilde[2:]).coef_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:23:01.082710Z",
     "start_time": "2020-06-12T16:23:01.078094Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = (fb['counts'][:-1] - fb['counts'].mean()).values.reshape(-1, 1)\n",
    "x_2 = (fb['counts'][:-2] - fb['counts'].mean()).values.reshape(-1, 1)\n",
    "x_3 = (fb['counts'][:-3] - fb['counts'].mean()).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:23:14.146863Z",
     "start_time": "2020-06-12T16:23:14.140713Z"
    }
   },
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()\n",
    "\n",
    "lr2.fit(np.concatenate([x_1[2:], x_2[1:], x_3], axis=1), y_tilde[3:]).coef_[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA Modeling \n",
    "'AR' is for \"Auto-Regressive\": The prediction for today will be a function of the value for previous days.\n",
    "\n",
    "The number of lag periods we want to include will be a parameter in the statsmodels model object (\"p\").\n",
    "\n",
    "In particular, auto-regressive models look like this:\n",
    "\n",
    "$X_t = \\beta_0 + \\Sigma^p_{i=1}\\beta_iX_{t-i} + \\epsilon_t$,\n",
    "where $\\epsilon_t$ should be more or less accurately modeled by white noise.\n",
    "\n",
    "We indicate how many terms our $AR$ model has by writing $AR(k)$ where $k$ is the number of terms.\n",
    "\n",
    "Looking at the PACF can help us decide on an appropriate $p$: We can look at where the correlation values cross the confidence thresholds.\n",
    "\n",
    "\n",
    "'MA' is for \"Moving Average\": The prediction for today will be a function of the rolling mean.\n",
    "\n",
    "The number of average terms we want to include will be a parameter in the statsmodels model object (\"q\").\n",
    "\n",
    "In particular, moving-average models look like this:\n",
    "\n",
    "$X_t = \\mu + \\epsilon_t + \\Sigma^q_{i=1}\\beta_i\\epsilon_{t-i}$,\n",
    "where again the $\\epsilon$ should be modeled by white noise.\n",
    "\n",
    "We indicate how many terms our $MA$ model has by writing $MA(k)$ where $k$ is the number of terms.\n",
    "\n",
    "Looking at the ACF can help us decide on an appropriate $q$: We can look at where the correlation values cross the confidence thresholds.\n",
    "The $AR$ and $MA$ models are intimately related. In fact $AR(p)$ is equivalent to $MA(\\infty)$ for any $p$. The reverse holds as well if $|\\theta| < 1$ for all $\\theta$ in $MA(q)$. For more on this, see [here](https://otexts.com/fpp2/MA.html).\n",
    "\n",
    "Consider $AR(1)$:\n",
    "\n",
    "$X_t = \\beta_0 + \\beta_1X_{t-1} + \\epsilon_t$ <br/> \n",
    "$= \\beta_0 + \\beta_1(\\beta_1X_{t-2} + \\epsilon_{t-1})$ <br/>\n",
    "$= \\beta_0 + \\beta_1^2X_{t-2} + \\beta_1\\epsilon_{t-1}$ <br/>\n",
    "$= \\beta_0 + \\beta_1^3X_{t-3} + \\beta_1^2\\epsilon_{t-2} + \\beta_1\\epsilon_{t-1}$\n",
    "\n",
    "In the limit of this expansion we obtain an expression for $MA(\\infty)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity and the Dickey-Fuller Test\n",
    "\n",
    "ARMA models assume that the time series is stationary, which means that its statistical properties are not a (meaningful) function of time. That is, the statistical properties of the series like mean, variance and autocorrelation are constant over time. A stationary time series is devoid of seasonal effects as well.\n",
    "\n",
    "It may seem counterintuitive that, for modeling purposes, we want our time series not to be a function of time! But the basic idea is that we want our datapoints to be mutually independent. Why? \n",
    "\n",
    "One way of testing for stationarity is to use the Dickey-Fuller Test. The statsmodels version returns the test statistic and a p-value, relative to the null hypothesis that the series in question is NOT stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:47:32.641554Z",
     "start_time": "2020-06-12T16:47:32.635712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Presumably, our football series is not stationary. Let's check.\n",
    "result = adfuller(fb['counts'], autolag=None)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:57:54.469603Z",
     "start_time": "2020-06-12T16:57:54.463262Z"
    }
   },
   "outputs": [],
   "source": [
    "#could try a log transform \n",
    "from numpy import log\n",
    "X = log(fb['counts'])\n",
    "result = adfuller(X, autolag=None)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:13:31.320395Z",
     "start_time": "2020-06-12T17:13:30.028103Z"
    }
   },
   "outputs": [],
   "source": [
    "#rolling mean \n",
    "roll_mean = fb['counts'].rolling(window=4).mean()\n",
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(fb['counts'], color='blue',label='Original')\n",
    "plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean & Standard Deviation')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:15:44.629819Z",
     "start_time": "2020-06-12T17:15:44.624391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subtract the moving average from the original data\n",
    "#we are taking the average of the last four values\n",
    "#the rolling mean is not defined for the first three values.\n",
    "data_minus_roll_mean = fb['counts'] - roll_mean\n",
    "data_minus_roll_mean.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:16:49.956248Z",
     "start_time": "2020-06-12T17:16:49.953297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the missing values from time series calculated above\n",
    "data_minus_roll_mean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:17:00.258680Z",
     "start_time": "2020-06-12T17:16:59.019108Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(data_minus_roll_mean, color='blue',label='Sales - rolling mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Sales while the rolling mean is subtracted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:18:46.092500Z",
     "start_time": "2020-06-12T17:18:46.087357Z"
    }
   },
   "outputs": [],
   "source": [
    "#differencing\n",
    "data_diff = fb['counts'].diff(periods=1)\n",
    "data_diff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:19:00.551862Z",
     "start_time": "2020-06-12T17:18:59.291226Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(data_diff, color='blue',label='Sales - rolling mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Differenced sales series')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:41:03.066756Z",
     "start_time": "2020-06-12T17:41:02.947908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate & fit model \n",
    "p = 3\n",
    "q = 1\n",
    "\n",
    "# This model will have three auto-regressive terms and one moving-average term.\n",
    "\n",
    "ar = ARMA(fb['counts'].diff().values[1:], (p, q)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:41:09.998439Z",
     "start_time": "2020-06-12T17:41:09.961192Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:59:18.344897Z",
     "start_time": "2020-06-12T17:59:18.338842Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_score(fb['counts'].diff().values[1:], ar.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
