{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"6\" color=\"blue\">Introducing Webscraping</font> ![](https://miro.medium.com/max/990/1*AaAIETIq7XNlLrFQW7BtZg.png)\n",
    "\n",
    "1. <font color=\"blue\" size=4>What is Web scraping?</font>\n",
    "    - Web scraping is a technique that allows you to extract data from websites and store it locally or in a database. It's also known as web harvesting, data scraping or data crawling. There is a lot of software out there that you can install and use to web scrape. Today, I'm going to introduce you to a super friendly and free python package called Beautiful Soup but Scrapy is another free package out there thats popular.\n",
    "    \n",
    "2. <font color=\"blue\" size=4>Why do we need to web scrape?</font>\n",
    "    - Why do we need to webscrape? Most websites only allow you to view data thru a web browser. They don't offer the functionality to save a copy of their data. Manually coping the data could take large amounts of time. Scraping software can automate the process and perform the task within a fraction of the time.\n",
    "    \n",
    "3. <font color=\"blue\" size=4>What are some common instances of webscraping?</font>\n",
    "    - **E-commerce Websites:** Web scrapers can collect the data specially related to the price of a specific product from various e-commerce websites for their comparison.\n",
    "    - **Content Aggregators:** Web scraping is used widely by content aggregators like news aggregators and job aggregators for providing updated data to their users.\n",
    "    - **Marketing and Sales Campaigns:** Web scrapers can be used to get the data like emails, phone number etc. for sales and marketing campaigns.\n",
    "    - **Data for Machine Learning Projects:** Retrieval of data for machine learning projects depends upon web scraping.\n",
    "    \n",
    "4. <font color=\"blue\" size=4>How do we scrape?</font>\n",
    "\n",
    "    What are the basic components of a web page? There are typically around 4 basic components of a web page.\n",
    "\n",
    "    - html - which contains the main content of a page\n",
    "    - css - adds styling to make the page pretty\n",
    "    - js - javascript files add interactivity to pages\n",
    "    - JPG & PNG - are image formats used to show pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"6\" color=\"blue\">HTML</font>\n",
    "\n",
    "Hypertext Markup Language is the expression of webpages. \n",
    "Its unlike python however in that it has no ability to rationalize. It can make text italicized or bold; it can create paragraphs; it cannot perform recursion. \n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>  \n",
    "<html>  \n",
    "    <!-- This is the syntax for adding helpful comments that will not be rendered to the browser -->\n",
    "    <head>   \n",
    "        \n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "        <!-- The following are html elements. There is a good resource for html documentation at the end of this notebook --> \n",
    "\n",
    "        <h1>My Heading</h1>\n",
    "        <p>My Paragraph</p>\n",
    "        \n",
    "    </body>\n",
    "\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To extract data using web scraping with python, you need to follow these basic steps:**\n",
    "\n",
    "1. <font color=\"blue\">Find the URL that you want to scrape</font>\n",
    "2. <font color=\"blue\">Inspect the Page</font>\n",
    "3. <font color=\"blue\">Find the data you want to extract</font>\n",
    "4. <font color=\"blue\">Build a simple scraper</font>\n",
    "5. <font color=\"blue\">Modify the scraper to get rid of html and extract all the useful data</font>\n",
    "6. <font color=\"blue\">Store the data in the required format</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T19:29:10.562271Z",
     "start_time": "2020-06-30T19:29:09.625711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amberyandow/anaconda3/envs/learn-env/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import re  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:40:45.188681Z",
     "start_time": "2020-06-30T17:40:44.893152Z"
    }
   },
   "source": [
    "<font face=\"verdana\" size=\"4\" color=\"blue\">Let's scrape some quotes from this website - http://quotes.toscrape.com/</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T18:41:41.931816Z",
     "start_time": "2020-06-30T18:41:41.929828Z"
    }
   },
   "outputs": [],
   "source": [
    "#build a simple soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"4\" color=\"blue\">Activity - Break off into groups and get the Authors</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T19:29:13.924406Z",
     "start_time": "2020-06-30T19:29:13.293199Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
